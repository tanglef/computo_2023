<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.8">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tanguy Lefort">
<meta name="author" content="Benjamin Charlier">
<meta name="author" content="Alexis Joly">
<meta name="author" content="Joseph Salmon">
<meta name="dcterms.date" content="2023-04-27">
<meta name="keywords" content="crowdsourcing, label noise, task difficulty, worker ability">
<meta name="description" content="Crowdsourcing is a quick and easy way to collect labels for large datasets, involving many workers. However, it is common for workers to disagree with each other. Sources of error can arise from the workers’ skills, but also from the intrinsic difficulty of the task. We introduce peerannot, a Python library for managing and learning from crowdsourced labels.">

<title>Peerannot: learning from crowdsourced image datasets with Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="content_files/libs/clipboard/clipboard.min.js"></script>
<script src="content_files/libs/quarto-html/quarto.js"></script>
<script src="content_files/libs/quarto-html/popper.min.js"></script>
<script src="content_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="content_files/libs/quarto-html/anchor.min.js"></script>
<link href="content_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="content_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="content_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="content_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="content_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #FFFFFF;
      }

      .quarto-title-block .quarto-title-banner {
        color: #FFFFFF;
background: #034E79;
      }
</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; Peerannot: learning from crowdsourced image datasets with Python</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> source</button></div></div>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons BY License"></a>
ISSN 2824-7795</p>
            <div>
        <div class="description">
          <p>Crowdsourcing is a quick and easy way to collect labels for large datasets, involving many workers. However, it is common for workers to disagree with each other. Sources of error can arise from the workers’ skills, but also from the intrinsic difficulty of the task. We introduce peerannot, a Python library for managing and learning from crowdsourced labels.</p>
        </div>
      </div>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-heading">Affiliations</div>
          
          <div class="quarto-title-meta-contents">
        <a href="https://tanglef.github.io">Tanguy Lefort</a> <a href="https://orcid.org/0009-0000-6710-3221" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://someplace.themoon.org">
                  Name of Affiliation one
                  </a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="https://imag.umontpellier.fr/~charlier/index.php?page=index&amp;lang=en">Benjamin Charlier</a> 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://someplace.themoon.org">
                  Name of Afficiliation two
                  </a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="http://www-sop.inria.fr/members/Alexis.Joly/wiki/pmwiki.php">Alexis Joly</a> <a href="https://orcid.org/0000-0002-2161-9940" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://someplace.themoon.org">
                  Name of Afficiliation two
                  </a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="http://josephsalmon.eu/">Joseph Salmon</a> <a href="https://orcid.org/0000-0002-3181-0634" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://someplace.themoon.org">
                  Name of Afficiliation two
                  </a>
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 27, 2023</p>
      </div>
    </div>
                                    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">April 27, 2023</p>
      </div>
    </div>
      
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">crowdsourcing, label noise, task difficulty, worker ability</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <p class="date">draft</p>
                  </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>Crowdsourcing is a quick and easy way to collect labels for large datasets, involving many workers. However, workers often disagree with each other. Sources of error can arise from the workers’ skills, but also from the intrinsic difficulty of the task. We present <code>peerannot</code>: a <code>Python</code> library for managing and learning from crowdsourced labels. Our library allows users to aggregate labels from common noise models or train a deep learning-based classifier directly from crowdsourced labels. In addition, we provide an identification module to easily explore the task difficulty of datasets and worker capabilities.</p>
    </div>
  </div>

  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction-crowdsourcing-in-image-classification" id="toc-introduction-crowdsourcing-in-image-classification" class="nav-link active" data-scroll-target="#introduction-crowdsourcing-in-image-classification">Introduction: crowdsourcing in image classification</a></li>
  <li><a href="#notation-and-package-structure" id="toc-notation-and-package-structure" class="nav-link" data-scroll-target="#notation-and-package-structure">Notation and package structure</a>
  <ul class="collapse">
  <li><a href="#crowdsourcing-notation" id="toc-crowdsourcing-notation" class="nav-link" data-scroll-target="#crowdsourcing-notation">Crowdsourcing notation</a></li>
  <li><a href="#storing-crowdsourced-datasets-in-peerannot" id="toc-storing-crowdsourced-datasets-in-peerannot" class="nav-link" data-scroll-target="#storing-crowdsourced-datasets-in-peerannot">Storing crowdsourced datasets in <code>peerannot</code></a></li>
  </ul></li>
  <li><a href="#aggregation-strategies-in-crowdsourcing" id="toc-aggregation-strategies-in-crowdsourcing" class="nav-link" data-scroll-target="#aggregation-strategies-in-crowdsourcing">Aggregation strategies in crowdsourcing</a>
  <ul class="collapse">
  <li><a href="#classical-models" id="toc-classical-models" class="nav-link" data-scroll-target="#classical-models">Classical models</a>
  <ul class="collapse">
  <li><a href="#majority-vote-mv" id="toc-majority-vote-mv" class="nav-link" data-scroll-target="#majority-vote-mv">Majority vote (MV)</a></li>
  <li><a href="#naive-soft-ns" id="toc-naive-soft-ns" class="nav-link" data-scroll-target="#naive-soft-ns">Naive soft (NS)</a></li>
  <li><a href="#dawid-and-skene-ds" id="toc-dawid-and-skene-ds" class="nav-link" data-scroll-target="#dawid-and-skene-ds">Dawid and Skene (DS)</a></li>
  <li><a href="#generative-model-of-labels-abilities-and-difficulties-glad" id="toc-generative-model-of-labels-abilities-and-difficulties-glad" class="nav-link" data-scroll-target="#generative-model-of-labels-abilities-and-difficulties-glad">Generative model of Labels, Abilities, and Difficulties (GLAD)</a></li>
  </ul></li>
  <li><a href="#sec-evaluation-aggregation" id="toc-sec-evaluation-aggregation" class="nav-link" data-scroll-target="#sec-evaluation-aggregation">Experiments and evaluation of label aggregation strategies</a>
  <ul class="collapse">
  <li><a href="#simulated-independent-mistakes" id="toc-simulated-independent-mistakes" class="nav-link" data-scroll-target="#simulated-independent-mistakes">Simulated independent mistakes</a></li>
  <li><a href="#simulated-mistakes-with-discrete-difficulty-levels-on-tasks" id="toc-simulated-mistakes-with-discrete-difficulty-levels-on-tasks" class="nav-link" data-scroll-target="#simulated-mistakes-with-discrete-difficulty-levels-on-tasks">Simulated mistakes with discrete difficulty levels on tasks</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#learning-from-crowdsourced-tasks" id="toc-learning-from-crowdsourced-tasks" class="nav-link" data-scroll-target="#learning-from-crowdsourced-tasks">Learning from crowdsourced tasks</a>
  <ul class="collapse">
  <li><a href="#classical-models-1" id="toc-classical-models-1" class="nav-link" data-scroll-target="#classical-models-1">Classical models</a></li>
  <li><a href="#prediction-error-when-learning-from-crowdsourced-tasks" id="toc-prediction-error-when-learning-from-crowdsourced-tasks" class="nav-link" data-scroll-target="#prediction-error-when-learning-from-crowdsourced-tasks">Prediction error when learning from crowdsourced tasks</a></li>
  <li><a href="#sec-real-datasets" id="toc-sec-real-datasets" class="nav-link" data-scroll-target="#sec-real-datasets">Use case with <code>peerannot</code> on real datasets</a></li>
  </ul></li>
  <li><a href="#exploring-crowdsourced-datasets" id="toc-exploring-crowdsourced-datasets" class="nav-link" data-scroll-target="#exploring-crowdsourced-datasets">Exploring crowdsourced datasets</a>
  <ul class="collapse">
  <li><a href="#exploring-tasks-difficulty" id="toc-exploring-tasks-difficulty" class="nav-link" data-scroll-target="#exploring-tasks-difficulty">Exploring tasks’ difficulty</a>
  <ul class="collapse">
  <li><a href="#cifar-1oh-dataset" id="toc-cifar-1oh-dataset" class="nav-link" data-scroll-target="#cifar-1oh-dataset">CIFAR-1OH dataset</a></li>
  <li><a href="#labelme-dataset" id="toc-labelme-dataset" class="nav-link" data-scroll-target="#labelme-dataset">LabelMe dataset</a></li>
  </ul></li>
  <li><a href="#exploring-workers-reliability" id="toc-exploring-workers-reliability" class="nav-link" data-scroll-target="#exploring-workers-reliability">Exploring workers’ reliability</a>
  <ul class="collapse">
  <li><a href="#cifar-10h" id="toc-cifar-10h" class="nav-link" data-scroll-target="#cifar-10h">CIFAR-10H</a></li>
  <li><a href="#labelme" id="toc-labelme" class="nav-link" data-scroll-target="#labelme">LabelMe</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">Bibliography</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="content.pdf"><i class="bi bi-file-pdf"></i>PDF (computo)</a></li></ul></div></nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



<section id="introduction-crowdsourcing-in-image-classification" class="level1" data-number="1">
<h1 data-number="1">Introduction: crowdsourcing in image classification</h1>
<p>Image datasets widely use crowdsourcing to collect labels, involving many workers that can annotate images for a small cost (or even free for instance in citizen science) and faster than using expert labeling. Many classical datasets considered in machine learning have been created with human intervention to create labels, such as CIFAR-<span class="math inline">10</span>, <span class="citation" data-cites="krizhevsky2009learning">(<a href="#ref-krizhevsky2009learning" role="doc-biblioref">Krizhevsky and Hinton 2009</a>)</span>, ImageNet <span class="citation" data-cites="imagenet_cvpr09">(<a href="#ref-imagenet_cvpr09" role="doc-biblioref">Deng et al. 2009</a>)</span> or <span class="citation" data-cites="Garcin_Joly_Bonnet_Affouard_Lombardo_Chouet_Servajean_Lorieul_Salmon2021">(<a href="#ref-Garcin_Joly_Bonnet_Affouard_Lombardo_Chouet_Servajean_Lorieul_Salmon2021" role="doc-biblioref">Garcin et al. 2021</a>)</span> in image classification, but also COCO <span class="citation" data-cites="cocodataset">(<a href="#ref-cocodataset" role="doc-biblioref">Lin et al. 2014</a>)</span>, solar photovoltaic arrays <span class="citation" data-cites="kasmi2023crowdsourced">(<a href="#ref-kasmi2023crowdsourced" role="doc-biblioref">Kasmi et al. 2023</a>)</span> or even macro litter <span class="citation" data-cites="chagneux2023">(<a href="#ref-chagneux2023" role="doc-biblioref">Chagneux et al. 2023</a>)</span> in image segmentation and object counting.</p>
<p>Crowdsourced datasets induce at least three major challenges to which we contribute with <code>peerannot</code>:</p>
<ol type="1">
<li><em>How to identify good workers in the crowd?</em> When multiple answers are given to a single task, looking for who to trust for which type of task becomes necessary to estimate the ground truth or later train a model with as few noise sources as possible. The module <code>identify</code> uses different scoring metrics to create a worker and/or task evaluation. This is particularly relevant considering the gamification of crowdsourcing experiments <span class="citation" data-cites="plantgame2016">(<a href="#ref-plantgame2016" role="doc-biblioref">Servajean et al. 2016</a>)</span></li>
<li><em>How to aggregate multiple labels into a single label from crowdsourced tasks?</em> This occurs for example when dealing with a single dataset that has been labeled by multiple workers with disagreements. This is also encountered with other scoring issues such as polls, reviews, peer-grading, <em>etc.</em> In our framework this is treated with the <code>aggregate</code> command, that given multiple labels, infers a ground truth label. From aggregated labels, a classifier can then be trained using the <code>train</code> command.</li>
<li><em>How to learn a classifier from crowdsourced datasets?</em> Where the first question is bound by aggregating multiple labels into a single one, this considers the case where we do not need a single label to train on, but instead train a classifier on the crowdsourced data, with the motivation to perform well on a testing set. This end-to-end vision, is common in machine learning, however, it requires the actual tasks (the images, texts, videos, <em>etc.</em>) to train on – and in crowdsourced datasets publicly available, they are not always available. This is treated with the <code>aggregate-deep</code> command.</li>
</ol>
<p>The library <code>peerannot</code> addresses these practical questions within a reproducible setting. Indeed, the complexity of experiments often leads to a lack of transparency and reproducible results for simulations and real datasets. We propose standard simulation settings with explicit implementation parameters that can be shared. For real datasets, <code>peerannot</code> is compatible with standard neural networks architectures from the <code>Torchvision</code> <span class="citation" data-cites="torchvision">(<a href="#ref-torchvision" role="doc-biblioref">Marcel and Rodriguez 2010</a>)</span> library and <code>Pytorch</code> <span class="citation" data-cites="pytorch">(<a href="#ref-pytorch" role="doc-biblioref">Paszke et al. 2019</a>)</span>, allowing a flexible framework with easy-to-share scripts to reproduce experiments.</p>
<div id="fig-pipeline" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./figures/strategiesbis.png" class="img-fluid figure-img" width="500"></p>
<figcaption class="figure-caption">Figure&nbsp;1: From crowdsourced labels to training a classifier neural network, the learning pipeline using the <code>peerannot</code> library. An optional preprocessing step using the <code>identify</code> command allows us to remove worse performing workers or images that can not be classified correctly (very bad quality for example). Then, from the cleaned dataset, if we want labels we use the <code>aggregate</code> command that follows the chosen strategy. From the aggregated labels we can train a neural network classifier with the <code>train</code> command. Otherwise, we can directly train a neural network classifier that takes into account the crowdsourcing setting in its architecture using <code>aggregate-deep</code>.</figcaption>
</figure>
</div>
</section>
<section id="notation-and-package-structure" class="level1" data-number="2">
<h1 data-number="2">Notation and package structure</h1>
<section id="crowdsourcing-notation" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="crowdsourcing-notation">Crowdsourcing notation</h2>
<p>Let us consider the classical supervised learning classification framework. A training set <span class="math inline">\mathcal{D}=\{(x_i, y_i^\star)\}_{i=1}^{n_{\text{task}}}</span> is composed of <span class="math inline">n_{\text{task}}</span> tasks <span class="math inline">x_i\in\mathcal{X}</span> (the feature space) with (unobserved) ground truth label <span class="math inline">y_i^\star \in [K]={1,\dots,K}</span> one of the <span class="math inline">K</span> possible classes. In the following, the tasks considered are generally RGB images. We use the notation <span class="math inline">\sigma</span> for the softmax function. We use the <span class="math inline">i</span> index notation to denote the tasks dimension and the <span class="math inline">j</span> index notation for the workers in the crowdsourcing experiment. Note that indices start at position <span class="math inline">1</span> in the equation to follow mathematical standard notation such as <span class="math inline">[K]=1,\dots,K</span> but it should be addressed that, as this is a <code>Python</code> library, in the code indices start at the <span class="math inline">0</span> position.</p>
<p>With crowdsourced data the ground truth of a task <span class="math inline">x_i</span>, denoted <span class="math inline">y_i^\star</span> is unknown, and there is no single label that can be trusted as in standard supervised learning (even on the train set!). Instead, there is a crowd of <span class="math inline">n_{\text{worker}}</span> workers from which multiple workers <span class="math inline">(w_j)_j</span> propose a label <span class="math inline">(y_i^{(j)})_j</span>. The set of workers answering the task <span class="math inline">x_i</span> is denoted by <span class="math inline">\mathcal{A}(x_i)=\{j\in[n_\text{worker}]: w_j \text{ answered }x_i\}</span>. The cardinal <span class="math inline">\vert \mathcal{A}(x_i)\vert</span> is called the feedback effort on the task <span class="math inline">x_i</span>. Note that the feedback effort can not exceed the total number of workers <span class="math inline">n_{\text{worker}}</span>. Similarly, one can adopt a worker point of view: the set of tasks answered by a worker <span class="math inline">w_j</span> is denoted <span class="math inline">\mathcal{T}(w_j)=\{i\in[n_\text{task}]: w_j \text{ answered } x_i\}</span>. The cardinal <span class="math inline">\vert \mathcal{T}(w_j)\vert</span> is called the workerload of <span class="math inline">w_j</span>. The final dataset can then be decomposed as: <span class="math display">
\mathcal{D}_{\text{train}} := \bigcup_{i\in[n_\text{task}]} \{(x_i, (y_i^{(j)}) \text{ for }j\in\mathcal{A}(x_i))\} = \bigcup_{j\in[n_\text{worker}]} \{(x_i, (y_i^{(j)})) \text{ for }i \in\mathcal{T}(w_j)\} \enspace.
</span></p>
<p>In this article, we do not address the setting where workers report their self-confidence <span class="citation" data-cites="YasminRomena2022ICIC">(<a href="#ref-YasminRomena2022ICIC" role="doc-biblioref">Yasmin et al. 2022</a>)</span>, nor settings where workers are presented a trapping set – <em>i.e</em> a subset of tasks where the ground truth is known to evaluate them with known labels <span class="citation" data-cites="khattak_toward_2017">(<a href="#ref-khattak_toward_2017" role="doc-biblioref">Khattak 2017</a>)</span>.</p>
</section>
<section id="storing-crowdsourced-datasets-in-peerannot" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="storing-crowdsourced-datasets-in-peerannot">Storing crowdsourced datasets in <code>peerannot</code></h2>
<p>Crowdsourced datasets come in various To store crowdsourcing datasets efficiently and in a standardized way, <code>peerannot</code> proposes the following structure, where each dataset equals a folder:</p>
<pre class="{bash}"><code>datasetname
      ├── train
      │     ├── class1
      │     │     ├─ imagename-&lt;key&gt;.png
      │     │     ├─ ...
      │     │     └─ anotherimagename-&lt;anotherkey&gt;.png
      │     ├── ...
      │     └── classK
      ├── val
      ├── test
      ├── metadata.json
      └── answers.json</code></pre>
<p>The <code>answers.json</code> file stores the different votes for each task as described in <a href="#fig-answers" class="quarto-xref">Figure&nbsp;2</a>. Thus, for example for an image named <code>smiley_face-1</code>, the associated labels are stored in the <code>answers.json</code> at the key numbered <code>1</code>. This key identification system allows us to track directly from the filename the crowdsourced labels without having to rely on multiple indexing files as can be traditionally proposed. Furthermore, storing labels in a dictionary is more memory-friendly than having an array of size <code>(n_task,n_worker)</code> and writing <code>-1</code> when the worker <span class="math inline">w_j</span> did not see the task <span class="math inline">x_i</span> and <span class="math inline">y_i^{(j)}</span> otherwise (used in recent works such as <span class="citation" data-cites="rodrigues2017learning">Rodrigues et al. (<a href="#ref-rodrigues2017learning" role="doc-biblioref">2017</a>)</span>).</p>
<div id="fig-answers" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="./figures/json_answers.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: From collected labels to data storage in the <code>answers.json</code> file for a binary classification (<span class="math inline">K=2</span>) on recognizing smiling faces. (left: how data is stored in <code>peerannot</code>, right: data collected)</figcaption>
</figure>
</div>
<p>In <a href="#fig-answers" class="quarto-xref">Figure&nbsp;2</a>, there are three tasks, <span class="math inline">n_{\text{worker}}=4</span> workers and <span class="math inline">K=2</span> classes. If the tasks (images) are available, they must be stored as it is usual to store <code>ImageFolder</code> datasets with <code>pytorch</code> into a <code>train</code>, <code>val</code> and <code>test</code> folder. Each image can have its name followed by its index in the <code>answers.json</code> file.</p>
<p>Finally, a <code>metadata.json</code> file includes relevant information related to the crowdsourcing experiment such as the number of workers, the number of tasks, <em>etc.</em> For example, a minimal <code>metadata.json</code> file for the toy dataset presented in <a href="#fig-answers" class="quarto-xref">Figure&nbsp;2</a> is:</p>
<pre class="{json}"><code>{
    "name": "toy-data",
    "n_classes": 2,
    "n_workers": 4,
    "n_tasks": 3
}</code></pre>
<p>The <code>toy-data</code> example dataset is available as example <a href="https://github.com/peerannot/peerannot/tree/main/datasets/toy-data">in the <code>peerannot</code> repository</a>. Classical datasets in crowdsourcing such as CIFAR-10H and LabelMe can be installed directly using <code>peerannot</code> (an example is provided in <a href="#sec-real-datasets" class="quarto-xref">Section&nbsp;4.3</a>)</p>
</section>
</section>
<section id="aggregation-strategies-in-crowdsourcing" class="level1" data-number="3">
<h1 data-number="3">Aggregation strategies in crowdsourcing</h1>
<p>The first question we address with <code>peerannot</code> is: <em>How to aggregate multiple labels into a single label from crowdsourced tasks?</em> The aggregation step can lead to two types of learnable labels <span class="math inline">\hat y_i\in\Delta_{K}</span> (where <span class="math inline">\Delta_{K}</span> is the simplex of dimension <span class="math inline">K-1</span> : <span class="math inline">\Delta_{K}=\{p \in [K]: \sum_{k=1}^K p_k = 1, p_k \geq 0 \}</span> ) depending on the use case for each task <span class="math inline">x_i</span>, <span class="math inline">i=1,\dots,n_{\text{task}}</span>:</p>
<ul>
<li>a <strong>hard</strong> label: <span class="math inline">\hat y_i</span> is a Dirac distribution, this can be encoded as a classical label in <span class="math inline">[K]</span>,</li>
<li>a <strong>soft</strong> label: <span class="math inline">\hat y_i\in\Delta_{K}</span> can any probability distribution (different from a Dirac distribution). In that case, each coefficient in <span class="math inline">\hat y_i</span> represents the probability to belong to the given class.</li>
</ul>
<p>Learning from soft labels has been shown to improve learning performance and make the classifier learn the task ambiguity <span class="citation" data-cites="zhang2017mixup peterson_human_2019 park2022calibration">(<a href="#ref-zhang2017mixup" role="doc-biblioref">Zhang et al. 2018</a>; <a href="#ref-peterson_human_2019" role="doc-biblioref">Peterson et al. 2019</a>; <a href="#ref-park2022calibration" role="doc-biblioref">Park and Caragea 2022</a>)</span>. However, crowdsourcing is often used as a stepping stone to creating a new dataset and we usually expect a classification dataset to associate a task <span class="math inline">x_i</span> to a single label and not a full probability distribution. In this case, we recommend in practice releasing the anonymous answered labels and the aggregation strategy used to reach a consensus on a single label. With <code>peerannot</code>, both soft and hard labels can be produced.</p>
<p>Note that when a strategy produces a soft label, a hard label can be induced by taking the mode, i.e., the class achieving the maximum probability.</p>
<section id="classical-models" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="classical-models">Classical models</h2>
<p>We list below the most classical aggregation strategies used in crowdsourcing.</p>
<section id="majority-vote-mv" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="majority-vote-mv">Majority vote (MV)</h3>
<p>While the most intuitive way to create a label from multiple answers for any type of crowdsourced task would be to take the majority vote (MV), this strategy has many shortcomings <span class="citation" data-cites="james1998majority">(<a href="#ref-james1998majority" role="doc-biblioref">James 1998</a>)</span> – there is no noise model, no worker reliability estimated, no task difficulty involved and especially no way to remove poorly performing workers. This baseline aggregation can be expressed as:</p>
<p><span class="math display">
\hat y_i^{\text{MV}} = \operatornamewithlimits{argmax}_{k\in[K]} \sum_{j\in\mathcal{A}(x_i)} 1_{\{y_i^{(j)}=k\}} \enspace.
</span></p>
</section>
<section id="naive-soft-ns" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="naive-soft-ns">Naive soft (NS)</h3>
<p>One pitfall with the MV is that the label produced is hard, hence the ambiguity is discarded by construction. To remedy this, the Naive Soft (NS) labeling consists in using the empirical frequency distribution as the task label:</p>
<p><span class="math display">
\hat y_i^{\text{NS}} = \bigg(\frac{1}{\vert\mathcal{A}(x_i)\vert}\sum_{j\in\mathcal{A}(x_i)} 1_{\{y_i^{(j)}=k\}} \bigg)_{j\in[K]} \enspace.
</span> With the NS label, we keep the ambiguity, but all workers and all tasks are put on the same level. In practice, it is known that each worker comes with their abilities, thus modeling this knowledge can produce better results.</p>
</section>
<section id="dawid-and-skene-ds" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="dawid-and-skene-ds">Dawid and Skene (DS)</h3>
<p>Going further into the aggregation, researchers began creating a noise model to take into account the workers’ abilities in the aggregation. These types of models are most often EM-based and one of the most studied <span class="citation" data-cites="gao2013minimax">(<a href="#ref-gao2013minimax" role="doc-biblioref">Gao and Zhou 2013</a>)</span> and applied <span class="citation" data-cites="servajean2017crowdsourcing rodrigues2018deep">(<a href="#ref-servajean2017crowdsourcing" role="doc-biblioref">Servajean et al. 2017</a>; <a href="#ref-rodrigues2018deep" role="doc-biblioref">Rodrigues and Pereira 2018</a>)</span> is the Dawid and Skene’s (DS) model <span class="citation" data-cites="dawid_maximum_1979">(<a href="#ref-dawid_maximum_1979" role="doc-biblioref">Dawid and Skene 1979</a>)</span>. Assuming the workers are answering tasks independently, this model boils down to model pairwise confusions between each possible class. Each worker <span class="math inline">w_j</span> is assigned a confusion matrix <span class="math inline">\pi^{(j)}\in\mathbb{R}^{K\times K}</span> such that <span class="math inline">\pi^{(j)}_{k,\ell} = \mathbb{P}(y_i^{(j)}=\ell\vert y_i^\star=k)</span>. The model assumes that the probability for a task <span class="math inline">x_i</span> to have true label <span class="math inline">y_i^\star=k</span> follows a multinomial distribution with probabilities <span class="math inline">\pi^{(j)}_{k,\bullet}</span> for each worker. Each class has a prevalence <span class="math inline">\rho_k=\mathbb{P}(y_i^\star=k)</span> to appear in the dataset. Using the independence between workers, we obtain the following likelihood to maximize (using the EM algorithm):</p>
<p><span class="math display">
\displaystyle\prod_{i\in [n_{\texttt{task}}]}\prod_{k \in [K]}\bigg[\rho_k\prod_{j\in [n_{\texttt{worker}}]}
    \prod_{k\in [K]}\big(\pi^{(j)}_{k, k}\big)^{1_{\{y_i^{(j)}=k\}}}
    \bigg]^{T_{ik}},
</span></p>
<p>with <span class="math inline">T_{i,k}=1_{\{y_i^{\star}=k \}}</span>. The final aggregated soft label is <span class="math inline">\hat y_i^{\text{DS}} = T_{i,\cdot}</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./figures/bayesien_plaque_ds.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Bayesian <a href="https://en.wikipedia.org/wiki/Plate_notation">plate notation</a> for the DS model</figcaption>
</figure>
</div>
<p>Many variants of the DS model have been proposed in the literature, using Dirichlet priors on the confusion matrices <span class="citation" data-cites="passonneau-carpenter-2014-benefits">(<a href="#ref-passonneau-carpenter-2014-benefits" role="doc-biblioref">Passonneau and Carpenter 2014</a>)</span>, using <span class="math inline">L</span> clusters of workers <span class="citation" data-cites="imamura2018analysis">(<a href="#ref-imamura2018analysis" role="doc-biblioref">Imamura, Sato, and Sugiyama 2018</a>)</span> with <span class="math inline">1\leq L\leq n_{\text{worker}}</span> (DSWC) or even faster implementation that produces only hard labels <span class="citation" data-cites="sinha2018fast">(<a href="#ref-sinha2018fast" role="doc-biblioref">Sinha, Rao, and Balasubramanian 2018</a>)</span>.</p>
</section>
<section id="generative-model-of-labels-abilities-and-difficulties-glad" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="generative-model-of-labels-abilities-and-difficulties-glad">Generative model of Labels, Abilities, and Difficulties (GLAD)</h3>
<p>Finally, we present the GLAD model <span class="citation" data-cites="whitehill_whose_2009">(<a href="#ref-whitehill_whose_2009" role="doc-biblioref">Whitehill et al. 2009</a>)</span> that not only takes into account the worker’s ability, but also the task difficulty in the noise model. Denoting <span class="math inline">\alpha_j\in\mathbb{R}</span> the worker ability (the higher the better) and <span class="math inline">\beta_i\in\mathbb{R}^+_\star</span> the task’s difficulty (the higher the easier), the model noise is:</p>
<p><span class="math display">
\mathbb{P}(y_i^{(j)}=y_i^\star\vert \alpha_j,\beta_i) = \frac{1}{1+\exp(-\alpha_j\beta_i)} \enspace.
</span> GLAD’s model also assumes that the errors are uniform across wrong labels, thus: <span class="math display">
\forall k \in [K],\ \mathbb{P}(y_i^{(j)}=k\vert y_i^\star\neq k,\alpha_j,\beta_i) = \frac{1}{K-1}\left(1-\frac{1}{1+\exp(-\alpha_j\beta_i)}\right)\enspace.
</span> The likelihood can then be optimized using an EM algorithm to recover the soft label <span class="math inline">\hat y_i^{\text{GLAD}}</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./figures/schema_bayesien_glad.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Bayesian <a href="https://en.wikipedia.org/wiki/Plate_notation">plate notation</a> for the GLAD model</figcaption>
</figure>
</div>
<p>All of these aggregation strategies – and more – are available in the <code>peerannot</code> library from the <code>peerannot.models</code> module. Each model is a class object in its own <code>Python</code> file. It inherits from the <code>CrowdModel</code> template class and is defined with at least two methods:</p>
<ul>
<li><code>run</code>: includes the optimization procedure to obtain needed weights (<em>e.g.</em> the EM algorithm for the DS model),</li>
<li><code>get_probas</code>: returns the soft labels output for each task.</li>
</ul>
</section>
</section>
<section id="sec-evaluation-aggregation" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-evaluation-aggregation">Experiments and evaluation of label aggregation strategies</h2>
<p>One way to evaluate the label aggregation strategies is to measure their accuracy. This means that the underlying ground truth must be known – or at least for a representative subset. As the set of <span class="math inline">n_{\text{task}}</span> can be seen as a training set for a future classifier, we denote this metric <span class="math inline">\operatornamewithlimits{AccTrain}</span> on a dataset <span class="math inline">\mathcal{D}</span> for a given aggregated label <span class="math inline">(\hat y_i)_i</span> as:</p>
<p><span class="math display">
\operatornamewithlimits{AccTrain}(\mathcal{D}) = \frac{1}{\vert \mathcal{D}\vert}\sum_{i=1}^{\vert\mathcal{D}\vert} 1_{\{y_i^\star=\operatornamewithlimits{argmax}_{k\in[K]}\hat y_i\}} \enspace.
</span></p>
<p>In the following, we write <span class="math inline">\operatornamewithlimits{AccTrain}</span> for <span class="math inline">\operatornamewithlimits{AccTrain}(\mathcal{D}_{\text{train}})</span> as we only consider the full training set so there is no ambiguity. While this metric is useful, in practice there are a few arguable issues:</p>
<ul>
<li>the <span class="math inline">\operatornamewithlimits{AccTrain}</span> does not consider the ambiguity of the soft label, only the most probable class, whereas in some contexts ambiguity can be informative,</li>
<li>in supervised learning one objective is to identify difficult or mislabeled tasks <span class="citation" data-cites="pleiss_identifying_2020 lefort2022improve">(<a href="#ref-pleiss_identifying_2020" role="doc-biblioref">Pleiss et al. 2020</a>; <a href="#ref-lefort2022improve" role="doc-biblioref">Lefort et al. 2022</a>)</span>, pruning those tasks can easily artificially improve the <span class="math inline">\operatornamewithlimits{AccTrain}</span>, but there is no guarantee over the predictive performance of a model based on the newly pruned dataset.</li>
</ul>
<p>We first consider classical simulation settings in the literature that can easily be created and reproduced using <code>peerannot</code>.</p>
<section id="simulated-independent-mistakes" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="simulated-independent-mistakes">Simulated independent mistakes</h3>
<p>The independent mistakes consider that each worker <span class="math inline">w_j</span> answers following a multinomial distribution with weights given at the row <span class="math inline">y_i^\star</span> of their confusion matrix <span class="math inline">\pi^{(j)}\in\mathbb{R}^{K\times K}</span>. Each confusion matrix is generated diagonally dominant. Answers are independent of one another as each matrix is generated independently and each worker answers independently of other workers. In this setting, the DS model is expected to perform the best with enough data as we are simulating data from its assumed noise model.</p>
<p>We simulate <span class="math inline">n_{\text{task}}=200</span> tasks and <span class="math inline">n_{\text{worker}}=30</span> workers with <span class="math inline">K=5</span> possible classes. Each task <span class="math inline">x_i</span> receives <span class="math inline">\vert\mathcal{A}(x_i)\vert=10</span> labels.</p>
<div class="cell" data-execution_count="1">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">30</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy independent<span class="op">-</span>confusion <span class="op">\</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>independent</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peerannot.helpers.helpers_visu <span class="im">import</span> feedback_effort, working_load</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> MaxNLocator</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.ticker <span class="im">as</span> mtick</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(plt.MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">8</span>, <span class="dv">12</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="content_files/figure-html/cell-3-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</p>
<div class="cell" data-execution_count="3">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=5]"</span>, <span class="st">"DSWC[L=10]"</span>]:</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>independent<span class="op">/</span> <span class="op">-</span>s {strat}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="4">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>simu_indep <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"independent"</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=5]"</span>: [], <span class="st">"dswc[l=10]"</span>: []}</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_indep <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_independent-confusion_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_indep <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>display(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_4ee23 th {
  text-align: center;
}
#T_4ee23_row0_col0, #T_4ee23_row0_col1, #T_4ee23_row0_col2, #T_4ee23_row0_col3, #T_4ee23_row0_col4, #T_4ee23_row0_col5 {
  text-align: center;
}
</style>

<div id="tbl-simu-independent" class="anchored">
<table id="T_4ee23" data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;1: AccTrain metric on simulated independent mistakes considering classical feature-blind label aggregation strategies</caption>
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_4ee23_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">MV</th>
<th id="T_4ee23_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">NAIVESOFT</th>
<th id="T_4ee23_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">GLAD</th>
<th id="T_4ee23_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">DS</th>
<th id="T_4ee23_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">DSWC[L=5]</th>
<th id="T_4ee23_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">DSWC[L=10]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_4ee23_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">AccTrain</td>
<td id="T_4ee23_row0_col0" class="data row0 col0">0.760</td>
<td id="T_4ee23_row0_col1" class="data row0 col1">0.760</td>
<td id="T_4ee23_row0_col2" class="data row0 col2">0.775</td>
<td id="T_4ee23_row0_col3" class="data row0 col3">0.890</td>
<td id="T_4ee23_row0_col4" class="data row0 col4">0.775</td>
<td id="T_4ee23_row0_col5" class="data row0 col5">0.770</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>As expected by the simulation framework, <a href="#tbl-simu-independent" class="quarto-xref">Table&nbsp;1</a> fits the DS model, thus leading to better accuracy to retrieve the simulated labels for the DS model. The MV aggregation does not consider any worker-ability scoring or the task’s difficulty and performs the worse.</p>
<p>Note that <code>peerannot</code> can also simulate datasets with an imbalanced number of votes (<em>i.e.</em> <span class="math inline">|\mathcal{A}(x_i)|\in [\texttt{feedback}]</span> chosen uniformly at random). For example:</p>
<div class="cell" data-execution_count="5">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">30</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy independent<span class="op">-</span>confusion <span class="op">\</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>imbalance<span class="op">-</span>votes <span class="op">\</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>independent<span class="op">-</span>imbalanced<span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent-imbalanced"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent-imbalanced"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(plt.MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="content_files/figure-html/cell-7-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</p>
<div class="cell" data-execution_count="7">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=5]"</span>, <span class="st">"DSWC[L=10]"</span>]:</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>independent<span class="op">-</span>imbalanced<span class="op">/</span> <span class="op">-</span>s {strat}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>simu_indep <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"independent-imbalanced"</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=5]"</span>: [], <span class="st">"dswc[l=10]"</span>: []}</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_indep <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_independent-confusion_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_indep <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>display(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_22b97 th {
  text-align: center;
}
#T_22b97_row0_col0, #T_22b97_row0_col1, #T_22b97_row0_col2, #T_22b97_row0_col3, #T_22b97_row0_col4, #T_22b97_row0_col5 {
  text-align: center;
}
</style>

<div id="tbl-simu-independent-imb" class="anchored">
<table id="T_22b97" data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;2: AccTrain metric on simulated independent mistakes with an imbalanced number of votes per task considering classical feature-blind label aggregation strategies</caption>
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_22b97_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">MV</th>
<th id="T_22b97_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">NAIVESOFT</th>
<th id="T_22b97_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">GLAD</th>
<th id="T_22b97_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">DS</th>
<th id="T_22b97_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">DSWC[L=5]</th>
<th id="T_22b97_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">DSWC[L=10]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_22b97_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">AccTrain</td>
<td id="T_22b97_row0_col0" class="data row0 col0">0.630</td>
<td id="T_22b97_row0_col1" class="data row0 col1">0.605</td>
<td id="T_22b97_row0_col2" class="data row0 col2">0.560</td>
<td id="T_22b97_row0_col3" class="data row0 col3">0.635</td>
<td id="T_22b97_row0_col4" class="data row0 col4">0.635</td>
<td id="T_22b97_row0_col5" class="data row0 col5">0.650</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>While more realistic, working with an imbalanced number of votes per task leads to disrupting orders of performance for most strategies. ### Simulated correlated mistakes</p>
<p>The correlated mistakes are also known as the student-teacher setting. Consider that the crowd of workers is divided into two categories: teachers and students such that <span class="math inline">n_{\text{teacher}} + n_{\text{student}}=n_{\text{worker}}</span>. Each student is randomly assigned to one teacher at the beginning of the experiment. We generate the (diagonally dominant) confusion matrices of each teacher and the students are associated with their’s teacher confusion matrix. Then, they all answer independently, following a multinomial distribution with weights given at the row <span class="math inline">y_i^\star</span> of their confusion matrix <span class="math inline">\pi^{(j)}\in\mathbb{R}^{K\times K}</span>.</p>
<p>We simulate <span class="math inline">n_{\text{task}}=200</span> tasks and <span class="math inline">n_{\text{worker}}=30</span> with <span class="math inline">80\%</span> of students in the crowd. There are <span class="math inline">K=5</span> possible classes. Each task receives <span class="math inline">\vert\mathcal{A}(x_i)\vert=10</span> labels.</p>
<div class="cell" data-execution_count="9">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">30</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy student<span class="op">-</span>teacher <span class="op">\</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>ratio <span class="fl">0.8</span> <span class="op">\</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>student_teacher</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="10">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"student_teacher"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"student_teacher"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(plt.MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">8</span>, <span class="dv">12</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="content_files/figure-html/cell-11-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</p>
<div class="cell" data-execution_count="11">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=5]"</span>, <span class="st">"DSWC[L=10]"</span>]:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>student_teacher<span class="op">/</span> <span class="op">-</span>s {strat}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="12">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>simu_corr <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"student_teacher"</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=5]"</span>: [], <span class="st">"dswc[l=10]"</span>: []}</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_corr <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_student-teacher_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_corr <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>display(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_0eb1f th {
  text-align: center;
}
#T_0eb1f_row0_col0, #T_0eb1f_row0_col1, #T_0eb1f_row0_col2, #T_0eb1f_row0_col3, #T_0eb1f_row0_col4, #T_0eb1f_row0_col5 {
  text-align: center;
}
</style>

<div id="tbl-simu-corr" class="anchored">
<table id="T_0eb1f" data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;3: AccTrain metric on simulated correlated mistakes considering classical feature-blind label aggregation strategies</caption>
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_0eb1f_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">MV</th>
<th id="T_0eb1f_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">NAIVESOFT</th>
<th id="T_0eb1f_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">GLAD</th>
<th id="T_0eb1f_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">DS</th>
<th id="T_0eb1f_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">DSWC[L=5]</th>
<th id="T_0eb1f_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">DSWC[L=10]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_0eb1f_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">AccTrain</td>
<td id="T_0eb1f_row0_col0" class="data row0 col0">0.680</td>
<td id="T_0eb1f_row0_col1" class="data row0 col1">0.690</td>
<td id="T_0eb1f_row0_col2" class="data row0 col2">0.645</td>
<td id="T_0eb1f_row0_col3" class="data row0 col3">0.755</td>
<td id="T_0eb1f_row0_col4" class="data row0 col4">0.795</td>
<td id="T_0eb1f_row0_col5" class="data row0 col5">0.815</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>With <a href="#tbl-simu-corr" class="quarto-xref">Table&nbsp;3</a>, we see that with correlated data (<span class="math inline">24</span> students and <span class="math inline">6</span> teachers), using <span class="math inline">5</span> confusion matrices with DSWC[L=5] outperforms the vanilla DS strategy that does not consider the correlations. And the best-performing method here estimates only <span class="math inline">10</span> confusion matrices (instead of <span class="math inline">30</span> for the vanilla DS model).</p>
</section>
<section id="simulated-mistakes-with-discrete-difficulty-levels-on-tasks" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="simulated-mistakes-with-discrete-difficulty-levels-on-tasks">Simulated mistakes with discrete difficulty levels on tasks</h3>
<p>For the final simulation setting, we consider the discrete difficulty presented in <span class="citation" data-cites="whitehill_whose_2009">Whitehill et al. (<a href="#ref-whitehill_whose_2009" role="doc-biblioref">2009</a>)</span>. Contrary to other simulations, we here consider that workers belong to two levels of abilities: or , and tasks have two levels of difficulty: or . The keyword <code>ratio-diff</code> indicates the prevalence of each level of difficulty, it is defined as the ratio of tasks over tasks:</p>
<p><span class="math display">
\texttt{ratio-diff} = \frac{\mathbb{P}(\texttt{easy})}{\mathbb{P}(\texttt{hard})} \text{ with } \mathbb{P}(\texttt{easy}) +\mathbb{P}(\texttt{hard}) = 1 \enspace.
</span></p>
<p>Difficulties are then drawn <a href="https://peerannot.github.io/datasets/simulate_discrete_difficulty/">following at random</a>. Tasks that are are answered correctly by every worker. Tasks that are are answered following the confusion matrix assigned to each worker. Each worker then answers independently to the presented tasks.</p>
<p>We simulate <span class="math inline">n_{\text{task}}=500</span> tasks and <span class="math inline">n_{\text{worker}}=100</span> with <span class="math inline">35\%</span> of good workers in the crowd and <span class="math inline">50\%</span> of easy tasks. There are <span class="math inline">K=5</span> possible classes. Each task receives <span class="math inline">\vert\mathcal{A}(x_i)\vert=10</span> labels.</p>
<div class="cell" data-execution_count="13">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">100</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy discrete<span class="op">-</span>difficulty <span class="op">\</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>ratio <span class="fl">0.35</span> <span class="op">--</span>ratio<span class="op">-</span>diff <span class="dv">1</span> <span class="op">\</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback <span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>discrete_difficulty</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="14">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"discrete_difficulty"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"discrete_difficulty"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">8</span>, <span class="dv">12</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="content_files/figure-html/cell-15-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</p>
<div class="cell" data-execution_count="15">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=2]"</span>, <span class="st">"DSWC[L=5]"</span>]:</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>discrete_difficulty<span class="op">/</span> <span class="op">-</span>s {strat}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="16">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>simu_corr <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"discrete_difficulty"</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=2]"</span>: [], <span class="st">"dswc[l=5]"</span>: []}</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_corr <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_discrete-difficulty_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_corr <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>display(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_f36a3 th {
  text-align: center;
}
#T_f36a3_row0_col0, #T_f36a3_row0_col1, #T_f36a3_row0_col2, #T_f36a3_row0_col3, #T_f36a3_row0_col4, #T_f36a3_row0_col5 {
  text-align: center;
}
</style>

<div id="tbl-simu-discrete-diff" class="anchored">
<table id="T_f36a3" data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;4: AccTrain metric on simulated mistakes when tasks are associated a difficulty level considering classical feature-blind label aggregation strategies</caption>
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_f36a3_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">MV</th>
<th id="T_f36a3_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">NAIVESOFT</th>
<th id="T_f36a3_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">GLAD</th>
<th id="T_f36a3_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">DS</th>
<th id="T_f36a3_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">DSWC[L=2]</th>
<th id="T_f36a3_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">DSWC[L=5]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_f36a3_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">AccTrain</td>
<td id="T_f36a3_row0_col0" class="data row0 col0">0.805</td>
<td id="T_f36a3_row0_col1" class="data row0 col1">0.790</td>
<td id="T_f36a3_row0_col2" class="data row0 col2">0.845</td>
<td id="T_f36a3_row0_col3" class="data row0 col3">0.810</td>
<td id="T_f36a3_row0_col4" class="data row0 col4">0.600</td>
<td id="T_f36a3_row0_col5" class="data row0 col5">0.660</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Finally, in this setting involving task difficulty coefficients, the only strategy that involves a latent variable for the task difficulty, knowing GLAD, outperforms the other strategies (see <a href="#tbl-simu-discrete-diff" class="quarto-xref">Table&nbsp;4</a>). Note that in this case, creating clusters of answers leads to worse decisions than an MV aggregation.</p>
<p>To summarize our simulations, we see that depending on workers answering strategies, different latent variable models perform best. However, these are unknown outside of a simulation framework, thus if we want to obtain labels from multiple responses, we need to investigate multiple models. This can be done easily with <code>peerannot</code> as we demonstrated using the <code>aggregate</code> module. However, one might not want to generate a label, simply learn a classifier to predict labels on unseen data. This leads us to another module part of <code>peerannot</code>.</p>
</section>
</section>
</section>
<section id="learning-from-crowdsourced-tasks" class="level1" data-number="4">
<h1 data-number="4">Learning from crowdsourced tasks</h1>
<p>Most often, tasks are crowdsourced to create a large training set as modern machine learning models require more and more data. The aggregation step then simply becomes the first step in the complete learning pipeline. However, instead of aggregating labels, modern neural networks let us directly train a classifier from multiple noisy labels.</p>
<section id="classical-models-1" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="classical-models-1">Classical models</h2>
<p>In recent years, directly learning a classifier from noisy labels was introduced. Two of the most used models: CrowdLayer <span class="citation" data-cites="rodrigues2018deep">(<a href="#ref-rodrigues2018deep" role="doc-biblioref">Rodrigues and Pereira 2018</a>)</span> and CoNAL <span class="citation" data-cites="chu2021learning">(<a href="#ref-chu2021learning" role="doc-biblioref">Chu, Ma, and Wang 2021</a>)</span>, are directly available in <code>peerannot</code>. These two learning strategies directly incorporate a DS-based noise model in the neural network’s architecture.</p>
<p><a href="https://github.com/peerannot/peerannot/blob/main/peerannot/models/agg_deep/Crowdlayer.py">CrowdLayer</a> trains a classifier with noisy labels as follows. Let the scores (logits) output of a given classifier neural network <span class="math inline">\mathcal{C}</span> be <span class="math inline">z_i=\mathcal{C}(x_i)</span>. Then CrowdLayer adds as a last layer <span class="math inline">\pi\in\mathbb{R}^{n_{\text{worker}}\times K\times K}</span>, the tensor of all <span class="math inline">\pi^{(j)}</span>s such that the crossentropy loss <span class="math inline">(\mathrm{CE})</span> is adapted to the crowdsourcing setting into <span class="math inline">\mathcal{L}_{CE}^{\text{CrowdLayer}}</span> and computed as: <span class="math display">
\mathcal{L}_{CE}^{\text{CrowdLayer}}(x_i) = \sum_{j\in\mathcal{A}(x_i)} \mathrm{CE}(\sigma\left(\pi^{(j)}\sigma\big(z_i\big)\right), y_i^{(j)}) \enspace,
</span> where the classical crossentropy loss for two distribution <span class="math inline">u,v \in\Delta_{K}</span> is defined as <span class="math inline">\mathrm{CE}(u, v) = \sum_{k\in[K]} u_k\log(v_k)</span>.</p>
<p>The confusion matrices are incorporated as is into the network architecture as a new layer to transform the output probabilities to match each worker’s answer. However, for some datasets, it was noticed that global confusion occurs between the proposed classes. It is the case for example in the LabelMe dataset <span class="citation" data-cites="rodrigues2017learning">(<a href="#ref-rodrigues2017learning" role="doc-biblioref">Rodrigues et al. 2017</a>)</span> where classes overlap. In this case, <span class="citation" data-cites="chu2021learning">Chu, Ma, and Wang (<a href="#ref-chu2021learning" role="doc-biblioref">2021</a>)</span> proposed to extend the CrowdLayer model by not only modeling the worker confusion matrices; but also a global confusion matrix <span class="math inline">\pi^g\in\mathbb{R}^{K\times K}</span>.</p>
<!-- ![Bayesian [plate notation](https://en.wikipedia.org/wiki/Plate_notation) for CoNAL model. Each worker is assigned a confusion matrix $\pi^{(j)}$. A global confusion matrix $\pi^g$ is shared between workers. A tradeoff between the global confusion and the local one is applied.](./figures/schema_bayesien_conal.png){#fig-conal fig-align="center"} -->
<p>Given the output <span class="math inline">z_i=\mathcal{C}(x_i)\in\mathbb{R}^K</span> of a given classifier and task, <a href="https://github.com/peerannot/peerannot/blob/main/peerannot/models/agg_deep/CoNAL.py">CoNAL</a> interpolates between the local confusion <span class="math inline">\pi^{(j)}z_i</span> and the global one <span class="math inline">\pi^gz_i</span>. The loss function is computed as follows: <span class="math display">
\begin{aligned}
&amp;\mathcal{L}_{CE}^{\text{CoNAL}}(x_i) = \sum_{j\in\mathcal{A}(x_i)} \mathrm{CE}(h_i^{(j)}, y_i^{(j)}) \enspace, \\
&amp;\text{with } h_i^{(j)} = \sigma\left(\big(\omega_i^{(j)} \pi^g + (1-\omega_i^{(j)})\pi^{(j)}\big)z_i\right) \enspace.
\end{aligned} \
</span></p>
<p>The interpolation weight <span class="math inline">\omega_i^{(j)}</span> is unobservable in practice. So, to compute <span class="math inline">h_i^{(j)}</span>, the weight is obtained through an auxiliary network. This network takes in input the image and worker information and outputs a task-related vector <span class="math inline">v_i</span> and a worker-related vector <span class="math inline">u_j</span> of the same dimension. Finally, <span class="math inline">w_i^{(j)}=(1+\exp(- u_j^\top v_i))^{-1}</span>.</p>
<p>Both CrowdLayer and CoNAL model worker confusions directly in the classifier’s weights to learn from the noisy collected labels and are available in <code>peerannot</code> as we will see in the following.</p>
</section>
<section id="prediction-error-when-learning-from-crowdsourced-tasks" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="prediction-error-when-learning-from-crowdsourced-tasks">Prediction error when learning from crowdsourced tasks</h2>
<p>The <span class="math inline">\mathrm{AccTrain}</span> metric presented in <a href="#sec-evaluation-aggregation" class="quarto-xref">Section&nbsp;3.2</a> might no longer be of interest when training a classifier. Classical error measurements involve a test dataset to estimate the generalization error. To do so, we present hereafter two error metrics. Assuming we trained our classifier <span class="math inline">f_\theta</span> on a training set:</p>
<ul>
<li>the test accuracy is computed as <span class="math inline">\frac{1}{n_{\text{test}}}\sum_{i=1}^{n_{\text{test}}}1_{\{y_i^\star = \widehat{f_\theta(x_i)}\}}</span></li>
<li>the expected calibration error <span class="citation" data-cites="guo_calibration_2017">(<a href="#ref-guo_calibration_2017" role="doc-biblioref">Guo et al. 2017</a>)</span> over <span class="math inline">M</span> equally spaced bins <span class="math inline">I_1,\dots,I_M</span>, computed as:</li>
</ul>
<p><span class="math display">
\mathrm{ECE} = \sum_{m=1}^M \frac{|B_m|}{n_{\text{task}}}|\mathrm{acc}(B_m)
- \mathrm{conf}(B_m)|\enspace,
</span></p>
<p>with <span class="math inline">B_m=\{x_i| \mathcal{C}(x_i)_{[1]}\in I_m\}</span> the tasks with predicted probability in the <span class="math inline">m</span>-th bin, <span class="math inline">\mathrm{acc}(B_m)</span> the accuracy of the network for the samples in <span class="math inline">B_m</span> and <span class="math inline">\mathrm{conf}(B_m)</span> the associated empirical confidence.</p>
<p>The accuracy represents how well the classifier generalizes, the expected calibration error (ECE) quantifies the deviation between the accuracy and the confidence of the classifier. Modern neural networks are known to often be overconfident in their predictions <span class="citation" data-cites="guo_calibration_2017">(<a href="#ref-guo_calibration_2017" role="doc-biblioref">Guo et al. 2017</a>)</span>. However, it has also been remarked that training on crowdsourced data, depending on the strategy, mitigates this confidence issue. That is why we propose to compare them both in our coming experiments. Note that the ECE error estimator is known to be biased <span class="citation" data-cites="gruber2022better">(<a href="#ref-gruber2022better" role="doc-biblioref">Gruber and Buettner 2022</a>)</span>. Smaller training sets are known to have a higher ECE estimation error. And in the crowdsourcing setting, openly available datasets are often quite small.</p>
</section>
<section id="sec-real-datasets" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-real-datasets">Use case with <code>peerannot</code> on real datasets</h2>
<p>Few real crowdsourcing experiments have been released publicly. Among the available ones, CIFAR-10H <span class="citation" data-cites="peterson_human_2019">(<a href="#ref-peterson_human_2019" role="doc-biblioref">Peterson et al. 2019</a>)</span> is one of the largest with <span class="math inline">10 000</span> tasks labeled by workers (the testing set of CIFAR-10). The main limitation of CIFAR-10H is that there are few disagreements between workers and a simple majority voting already leads to a near-perfect <span class="math inline">\mathrm{AccTrain}</span> error. Hence, comparing the impact of aggregation and end-to-end strategies might not be relevant <span class="citation" data-cites="peterson_human_2019 aitchison2020statistical">(<a href="#ref-peterson_human_2019" role="doc-biblioref">Peterson et al. 2019</a>; <a href="#ref-aitchison2020statistical" role="doc-biblioref">Aitchison 2021</a>)</span>, it is however a good benchmark for task difficulty identification and worker evaluation scoring</p>
<p>The LabelMe dataset was extracted from crowdsourcing segmentation experiments and a subset of <span class="math inline">K=8</span> classes was released in <span class="citation" data-cites="rodrigues2017learning">Rodrigues et al. (<a href="#ref-rodrigues2017learning" role="doc-biblioref">2017</a>)</span>.</p>
<p>To install these datasets, we run the <code>install</code> command from <code>peerannot</code>:</p>
<div class="cell" data-execution_count="17">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot install .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span>labelme.py</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot install .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span>cifar10h.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let us use <code>peerannot</code> to train a Resnet34 on the LabelMe dataset for:</p>
<ul>
<li>aggregation strategies: MV, NS, DS, GLAD,</li>
<li>end-to-end strategies: CrowdLayer and CoNAL.</li>
</ul>
<p>As we can see, CoNAL strategy performs best. In this case, it is expected behavior as CoNAL was created for the LabelMe dataset. However, using <code>peerannot</code> we can look into <strong>why modeling common confusion returns better results with this dataset</strong>. To do so, we can explore the datasets from two points of view: worker-wise or task-wise.</p>
</section>
</section>
<section id="exploring-crowdsourced-datasets" class="level1" data-number="5">
<h1 data-number="5">Exploring crowdsourced datasets</h1>
<p>If a dataset requires citizen knowledge to be labeled, it is because expert knowledge is long and costly to obtain. In the era of big data, where datasets are built using web scraping (or using a platform like <a href="https://www.mturk.com/">Amazon Mechanical Turk</a>), citizen science is popular as it is an easy way to produce many labels.</p>
<p>However, mistakes and confusions happen during these experiments. Sometimes involuntarily (<em>e.g.</em> because the task is too hard or the worker is unable to differentiate between two classes) and sometimes not (<em>e.g.</em> the worker is a spammer).</p>
<p>Underlying all the learning models and aggregation strategies, the cornerstone of crowdsourcing is evaluating the trust we put in each worker depending on the presented task. And with the gamification of crowdsourcing <span class="citation" data-cites="plantgame2016 tinati2017investigation">(<a href="#ref-plantgame2016" role="doc-biblioref">Servajean et al. 2016</a>; <a href="#ref-tinati2017investigation" role="doc-biblioref">Tinati et al. 2017</a>)</span>, it has become essential to find scoring metrics both for workers and tasks to keep citizens in the loop so to speak. This is the purpose of the identification module in <code>peerannot</code></p>
<p>Our test cases are both the CIFAR-10H dataset and the LabelMe dataset to compare the worker and task evaluation depending on the number of votes collected. Indeed, the LabelMe dataset has only up to three votes per task whereas CIFAR-10H accounts for nearly fifty votes per task.</p>
<section id="exploring-tasks-difficulty" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="exploring-tasks-difficulty">Exploring tasks’ difficulty</h2>
<p>To explore the tasks’ intrinsic difficulty, we propose to compare three scoring metrics:</p>
<ul>
<li>the entropy of the NS distribution: reliable with a big enough and not adversarial crowd, the entropy measures the inherent uncertainty of the distribution to the possible outcomes.</li>
<li>GLAD’s scoring: by construction, <span class="citation" data-cites="whitehill_whose_2009">Whitehill et al. (<a href="#ref-whitehill_whose_2009" role="doc-biblioref">2009</a>)</span> introduced a scalar coefficient to score the difficulty of a task <span class="math inline">\beta_i&gt;0</span>.</li>
<li>the WAUM: introduced in <span class="citation" data-cites="lefort2022improve">(<a href="#ref-lefort2022improve" role="doc-biblioref">Lefort et al. 2022</a>)</span>, this weighted area under the margins indicates how difficult it is for a model to classify the task given the crowdsourced labels and the trust we have in each worker.</li>
</ul>
<p>Note that each of these statistics is useful in its context. The entropy can not be used in a setting with small <span class="math inline">|\mathcal{A}(x_i)|</span> (few labels per task), in particular for the LabelMe dataset it is uninformative. The WAUM can handle any number of labels, but the larger the better. However, as it uses a deep learning classifier, the WAUM needs the tasks <span class="math inline">(x_i)_i</span> in addition to the proposed labels while the other strategies are feature-blind.</p>
<section id="cifar-1oh-dataset" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="cifar-1oh-dataset">CIFAR-1OH dataset</h3>
<p>First, let us consider a dataset with a large number of tasks, annotations and workers: the CIFAR-10H dataset by <span class="citation" data-cites="peterson_human_2019">Peterson et al. (<a href="#ref-peterson_human_2019" role="doc-biblioref">2019</a>)</span>.</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>nrow <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>ncol <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        nrow,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        ncol,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        sharey<span class="op">=</span><span class="st">"row"</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        sharex<span class="op">=</span><span class="st">"col"</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">8</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>match_ <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"bird"</span>, <span class="dv">1</span>: <span class="st">"car"</span>, <span class="dv">2</span>: <span class="st">"cat"</span>, <span class="dv">3</span>: <span class="st">"deer"</span>, <span class="dv">4</span>: <span class="st">"dog"</span>, <span class="dv">5</span>: <span class="st">"frog"</span>, <span class="dv">6</span>: <span class="st">"horse"</span>, <span class="dv">7</span>: <span class="st">"plane"</span>, <span class="dv">8</span>: <span class="st">"ship"</span>, <span class="dv">9</span>: <span class="st">"truck"</span>}</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"cifar10H"</span> <span class="op">/</span> <span class="st">"train"</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nrow):</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  img_folder <span class="op">=</span> path <span class="op">/</span> <span class="ss">f"</span><span class="sc">{</span>match_[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>  all_imgs <span class="op">=</span> <span class="bu">list</span>(img_folder.glob(<span class="st">"*"</span>))[:ncol]</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(ncol):</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> np.asarray(Image.<span class="bu">open</span>(path <span class="op">/</span> all_imgs[j]))</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    axs[i,j].imshow(image, aspect<span class="op">=</span><span class="st">"equal"</span>)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    axs[i,j].axis(<span class="st">"off"</span>)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    axs[i,j].set_yticklabels([])</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=</span><span class="fl">0.05</span>, bottom<span class="op">=</span><span class="fl">0.05</span>, right<span class="op">=</span><span class="fl">0.95</span>, top<span class="op">=</span><span class="fl">0.95</span>, wspace<span class="op">=</span><span class="fl">0.05</span>, hspace<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="content_files/figure-html/cell-19-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Example of images to label from the CIFAR-10H dataset with label <code>bird</code>, <code>car</code>, <code>cat</code>, <code>deer</code>and <code>dog</code> (top to bottom) by row.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-execution_count="19">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>cifar10H <span class="op">-</span>s entropy <span class="op">-</span>K <span class="dv">10</span> <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span>answers.json</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span> <span class="op">-</span>s GLAD</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="20">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> corrfunc(x, y, ax<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kws):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    r, _ <span class="op">=</span> pearsonr(x, y)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> ax <span class="kw">or</span> plt.gca()</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    ax.annotate(<span class="vs">rf'Corr. = </span><span class="sc">{</span>r<span class="sc">:.2f}</span><span class="vs">'</span>, xy<span class="op">=</span>(<span class="fl">.1</span>, <span class="fl">.9</span>), xycoords<span class="op">=</span>ax.transAxes)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">'GLAD difficulty'</span>: [], <span class="st">"Entropy"</span>: []}</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"cifar10H"</span> <span class="op">/</span> <span class="st">"identification"</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"Entropy"</span>] <span class="op">=</span> np.load(path <span class="op">/</span> <span class="st">'entropies.npy'</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"GLAD difficulty"</span>] <span class="op">=</span> np.exp(np.load(path <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"difficulties.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># results["waum"] = pd.read_csv(path / "resnet34" / "waum_0.01_yang" / 'waum.csv')["waum"].values</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># axes = g.axes.flatten()</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># for i, ax in enumerate(axes):</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co">#   if i % len(results) == 0:</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-difficulty-c10h" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-difficulty-c10h-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Comparison of metrics scoring the task’s intrinsic difficulty in CIFAR-10H dataset.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="labelme-dataset" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="labelme-dataset">LabelMe dataset</h3>
<p>As for the LabelMe dataset, one difficulty in evaluating tasks’ intrinsic difficulty is that there are up to three votes given per task. Hence, the entropy in the distribution of the votes is no longer a reliable metric, and we need to rely on other models.</p>
<div class="cell" data-execution_count="21">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>nrow <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>ncol <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        nrow,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        ncol,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        sharey<span class="op">=</span><span class="st">"row"</span>,</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        sharex<span class="op">=</span><span class="st">"col"</span>,</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">8</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>match_ <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"coast"</span>, <span class="dv">1</span>: <span class="st">"forest"</span>, <span class="dv">2</span>: <span class="st">"highway"</span>, <span class="dv">3</span>: <span class="st">"insidecity"</span>, <span class="dv">4</span>: <span class="st">"mountain"</span>, <span class="dv">5</span>: <span class="st">"opencountry"</span>, <span class="dv">6</span>: <span class="st">"street"</span>, <span class="dv">7</span>: <span class="st">"tallbuilding"</span>}</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"labelme"</span> <span class="op">/</span> <span class="st">"train"</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nrow):</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>  img_folder <span class="op">=</span> path <span class="op">/</span> <span class="ss">f"</span><span class="sc">{</span>match_[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>  all_imgs <span class="op">=</span> <span class="bu">list</span>(img_folder.glob(<span class="st">"*"</span>))[:ncol]</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(ncol):</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> np.asarray(Image.<span class="bu">open</span>(path <span class="op">/</span> all_imgs[j]))</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    axs[i,j].imshow(image, aspect<span class="op">=</span><span class="st">"equal"</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    axs[i,j].axis(<span class="st">"off"</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    axs[i,j].set_yticklabels([])</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=</span><span class="fl">0.05</span>, bottom<span class="op">=</span><span class="fl">0.05</span>, right<span class="op">=</span><span class="fl">0.95</span>, top<span class="op">=</span><span class="fl">0.95</span>, wspace<span class="op">=</span><span class="fl">0.05</span>, hspace<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="content_files/figure-html/cell-22-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Example of images to label from the LabelMe dataset with label <code>coast</code>, <code>forest</code>, <code>highway</code>, <code>insidecity</code>and <code>mountain</code> (top to bottom) by row.</figcaption>
</figure>
</div>
</div>
</div>
<p>Now, let us compare the tasks’ difficulty distribution depending on the strategy considered using <code>peerannot</code>.</p>
<div class="cell" data-execution_count="22">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">-</span>s entropy <span class="op">-</span>K <span class="dv">10</span> <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span>answers.json</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">-</span>s GLAD</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can see in <a href="#fig-difficulty-labelme" class="quarto-xref">Figure&nbsp;4</a> that because the number of labels given per task is in <span class="math inline">\{1,2,3\}</span>, the entropy only takes four values and thus does not help to dissociate the tasks. In particular, tasks with only one label all have a null entropy, so not just consensual tasks.</p>
<div class="cell" data-execution_count="23">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> corrfunc(x, y, ax<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kws):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    r, _ <span class="op">=</span> pearsonr(x, y)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> ax <span class="kw">or</span> plt.gca()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    ax.annotate(<span class="vs">rf'Corr. = </span><span class="sc">{</span>r<span class="sc">:.2f}</span><span class="vs">'</span>, xy<span class="op">=</span>(<span class="fl">.1</span>, <span class="fl">.1</span>), xycoords<span class="op">=</span>ax.transAxes)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">'GLAD difficulty'</span>: [], <span class="st">"Entropy"</span>: []}</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"labelme"</span> <span class="op">/</span> <span class="st">"identification"</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"Entropy"</span>] <span class="op">=</span> np.load(path <span class="op">/</span> <span class="st">'entropies.npy'</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"GLAD difficulty"</span>] <span class="op">=</span> np.exp(np.load(path <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"difficulties.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-difficulty-labelme" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-difficulty-labelme-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Comparison of metrics scoring the task’s intrinsic difficulty.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="exploring-workers-reliability" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="exploring-workers-reliability">Exploring workers’ reliability</h2>
<p>From the labels, we can explore different worker evaluation scores. GLAD’s strategy estimates a reliability scalar coefficient <span class="math inline">\alpha_j</span> per worker. With strategies looking to estimate confusion matrices, we investigate two scoring rules for workers:</p>
<ul>
<li>the trace of the confusion matrix: the closer to K the better the worker,</li>
<li>the spammer score <span class="citation" data-cites="raykar_ranking_2011">(<a href="#ref-raykar_ranking_2011" role="doc-biblioref">Raykar and Yu 2011</a>)</span> that is the Frobenius norm between the estimated confusion matrix <span class="math inline">\hat\pi^{(j)}</span> and the closest rank-<span class="math inline">1</span> matrix. The further to zero the better the worker.</li>
</ul>
<p>When the tasks are available, confusion-matrix-based deep learning models can also be of use. We thus add to the comparison the trace of the confusion matrices with CrowdLayer and CoNAL on the datasets. For CoNAL, we only consider the trace of the confusion matrix <span class="math inline">\pi^{(j)}</span> in the pairwise comparison, and provide the common confusion matrix <span class="math inline">\pi^g</span> as separate.</p>
<section id="cifar-10h" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="cifar-10h">CIFAR-10H</h3>
<p>The Cifar-10H dataset has few disagreements among workers. From <strong>?@fig-abilities-cifar10H</strong>, we can see that in this dataset, different methods easily separate the worse workers from the rest of the crowd (workers in the tail of the distribution). However, these strategies disagree on the ranking of good against best workers as they do not measure the same properties.</p>
<div class="cell" data-execution_count="24">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span> <span class="op">-</span>s GLAD</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method <span class="kw">in</span> [<span class="st">"trace_confusion"</span>, <span class="st">"spam_score"</span>]:</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span> <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                       <span class="op">-</span>s {method} <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span>answers.json</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="25">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>path_ <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"cifar10H"</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> {<span class="st">"trace_confusion"</span>: [], <span class="st">"spam_score"</span>: [], <span class="st">"glad"</span>: []}</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"trace_confusion"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"traces_confusion.npy"</span>))</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"spam_score"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"spam_score.npy"</span>))</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"glad"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"abilities.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> pd.DataFrame(results_identif)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results_identif, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-abilities-cifar10h" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-abilities-cifar10h-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Comparison of ability scores by workers for the CIFAR-10H dataset.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="labelme" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="labelme">LabelMe</h3>
<p>Finally, let us evaluate workers for the LabelMe dataset. Because of the lack of data,</p>
<div class="cell" data-execution_count="26">
<details open="">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">-</span>s GLAD</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method <span class="kw">in</span> [<span class="st">"trace_confusion"</span>, <span class="st">"spam_score"</span>]:</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>                       <span class="op">-</span>s {method} <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span>answers.json</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="27">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>path_ <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"labelme"</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> {<span class="st">"trace_confusion"</span>: [], <span class="st">"spam_score"</span>: [], <span class="st">"glad"</span>: []}</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"trace_confusion"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"traces_confusion.npy"</span>))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"spam_score"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"spam_score.npy"</span>))</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"glad"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"abilities.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> pd.DataFrame(results_identif)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results_identif, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-abilities-labelme" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-abilities-labelme-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Comparison of ability scores by workers for the labelme dataset.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level1" data-number="6">
<h1 data-number="6">Conclusion</h1>
<p>We introduced <code>peerannot</code>, a library to handle crowdsourced datasets. This library enables both easy label aggregation and direct training strategies with classical state-of-the-art classifiers. The identification module of the library allows exploring the collected data from both the tasks and the workers’ point of view for better scorings and data cleaning procedures. Our library also comes with templated datasets to better share crowdsourced datasets and have strategies more uniform to test on.</p>
<p>We hope that this library helps reproducibility in the crowdsourcing community and also standardizes training from crowdsourced datasets. New strategies can easily be incorporated into the open-source code <a href="https://github.com/peerannot/peerannot">available on github</a>. Finally, as <code>peerannot</code> is mostly directed to handle classification datasets, one of our future works would be to consider other <code>peerannot</code> modules to handle crowdsourcing for object detection, segmentation and even worker evaluation in other contexts like peer-grading.</p>
<!-- -->

</section>
<section id="bibliography" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-aitchison2020statistical" class="csl-entry" role="listitem">
Aitchison, Laurence. 2021. <span>“A Statistical Theory of Cold Posteriors in Deep Neural Networks.”</span> In <em>ICLR</em>.
</div>
<div id="ref-chagneux2023" class="csl-entry" role="listitem">
Chagneux, Mathis, Sylvain LeCorff, Pierre Gloaguen, Charles Ollion, Océane Lepâtre, and Antoine Bruge. 2023. <span>“Macrolitter Video Counting on Riverbanks Using State Space Models and Moving Cameras.”</span> <em>Computo</em>, February. <a href="https://doi.org/10.57750/845m-f805">https://doi.org/10.57750/845m-f805</a>.
</div>
<div id="ref-chu2021learning" class="csl-entry" role="listitem">
Chu, Zhendong, Jing Ma, and Hongning Wang. 2021. <span>“Learning from Crowds by Modeling Common Confusions.”</span> In <em>AAAI</em>, 5832–40.
</div>
<div id="ref-dawid_maximum_1979" class="csl-entry" role="listitem">
Dawid, AP, and AM Skene. 1979. <span>“Maximum Likelihood Estimation of Observer Error-Rates Using the <span>EM</span> Algorithm.”</span> <em>J. R. Stat. Soc. Ser. C. Appl. Stat.</em> 28 (1): 20–28.
</div>
<div id="ref-imagenet_cvpr09" class="csl-entry" role="listitem">
Deng, J., W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. 2009. <span>“ImageNet: A Large-Scale Hierarchical Image Database.”</span> In <em>CVPR</em>.
</div>
<div id="ref-gao2013minimax" class="csl-entry" role="listitem">
Gao, Chao, and Dengyong Zhou. 2013. <span>“Minimax Optimal Convergence Rates for Estimating Ground Truth from Crowdsourced Labels.”</span> <em>arXiv Preprint arXiv:1310.5764</em>.
</div>
<div id="ref-Garcin_Joly_Bonnet_Affouard_Lombardo_Chouet_Servajean_Lorieul_Salmon2021" class="csl-entry" role="listitem">
Garcin, C., A. Joly, P. Bonnet, A. Affouard, J.-C. Lombardo, M. Chouet, M. Servajean, T. Lorieul, and J. Salmon. 2021. <span>“Pl@ntNet-300K: A Plant Image Dataset with High Label Ambiguity and a Long-Tailed Distribution.”</span> In <em>Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks</em>.
</div>
<div id="ref-gruber2022better" class="csl-entry" role="listitem">
Gruber, Sebastian Gregor, and Florian Buettner. 2022. <span>“Better Uncertainty Calibration via Proper Scores for Classification and Beyond.”</span> In <em>Advances in Neural Information Processing Systems</em>.
</div>
<div id="ref-guo_calibration_2017" class="csl-entry" role="listitem">
Guo, C, G Pleiss, Y Sun, and KQ Weinberger. 2017. <span>“On Calibration of Modern Neural Networks.”</span> In <em>ICML</em>, 1321.
</div>
<div id="ref-imamura2018analysis" class="csl-entry" role="listitem">
Imamura, Hideaki, Issei Sato, and Masashi Sugiyama. 2018. <span>“Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model.”</span> In <em>ICML</em>, 2147–56.
</div>
<div id="ref-james1998majority" class="csl-entry" role="listitem">
James, Gareth Michael. 1998. <span>“Majority Vote Classifiers: Theory and Applications.”</span> PhD thesis, Stanford University.
</div>
<div id="ref-kasmi2023crowdsourced" class="csl-entry" role="listitem">
Kasmi, Gabriel, Yves-Marie Saint-Drenan, David Trebosc, Raphaël Jolivet, Jonathan Leloux, Babacar Sarr, and Laurent Dubus. 2023. <span>“A Crowdsourced Dataset of Aerial Images with Annotated Solar Photovoltaic Arrays and Installation Metadata.”</span> <em>Scientific Data</em> 10 (1): 59.
</div>
<div id="ref-khattak_toward_2017" class="csl-entry" role="listitem">
Khattak, Faiza Khan. 2017. <span>“Toward a Robust and Universal Crowd Labeling Framework.”</span> PhD thesis, Columbia University.
</div>
<div id="ref-krizhevsky2009learning" class="csl-entry" role="listitem">
Krizhevsky, Alex, and Geoffrey Hinton. 2009. <span>“Learning Multiple Layers of Features from Tiny Images.”</span> University of Toronto.
</div>
<div id="ref-lefort2022improve" class="csl-entry" role="listitem">
Lefort, Tanguy, Benjamin Charlier, Alexis Joly, and Joseph Salmon. 2022. <span>“Identify Ambiguous Tasks Combining Crowdsourced Labels by Weighting Areas Under the Margin.”</span> <em>arXiv Preprint arXiv:2209.15380</em>.
</div>
<div id="ref-cocodataset" class="csl-entry" role="listitem">
Lin, Tsung-Yi, Michael Maire, Serge J. Belongie, Lubomir D. Bourdev, Ross B. Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll’a r, and C. Lawrence Zitnick. 2014. <span>“Microsoft <span>COCO:</span> Common Objects in Context.”</span> <em>CoRR</em> abs/1405.0312. <a href="http://arxiv.org/abs/1405.0312">http://arxiv.org/abs/1405.0312</a>.
</div>
<div id="ref-torchvision" class="csl-entry" role="listitem">
Marcel, Sébastien, and Yann Rodriguez. 2010. <span>“Torchvision the Machine-Vision Package of Torch.”</span> In <em>Proceedings of the 18th ACM International Conference on Multimedia</em>, 1485–88. MM ’10. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/1873951.1874254">https://doi.org/10.1145/1873951.1874254</a>.
</div>
<div id="ref-park2022calibration" class="csl-entry" role="listitem">
Park, Seo Yeon, and Cornelia Caragea. 2022. <span>“On the Calibration of Pre-Trained Language Models Using Mixup Guided by Area Under the Margin and Saliency.”</span> In <em>ACML</em>, 5364–74.
</div>
<div id="ref-passonneau-carpenter-2014-benefits" class="csl-entry" role="listitem">
Passonneau, Rebecca J., and Bob Carpenter. 2014. <span>“The Benefits of a Model of Annotation.”</span> <em>Transactions of the Association for Computational Linguistics</em> 2: 311–26.
</div>
<div id="ref-pytorch" class="csl-entry" role="listitem">
Paszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, et al. 2019. <span>“PyTorch: An Imperative Style, High-Performance Deep Learning Library.”</span> In <em>NeurIPS</em>, 8024–35.
</div>
<div id="ref-peterson_human_2019" class="csl-entry" role="listitem">
Peterson, Joshua C., Ruairidh M. Battleday, Thomas L. Griffiths, and Olga Russakovsky. 2019. <span>“Human Uncertainty Makes Classification More Robust.”</span> In <em>ICCV</em>, 9617–26.
</div>
<div id="ref-pleiss_identifying_2020" class="csl-entry" role="listitem">
Pleiss, Geoff, Tianyi Zhang, Ethan R Elenberg, and Kilian Q Weinberger. 2020. <span>“Identifying Mislabeled Data Using the Area Under the Margin Ranking.”</span> In <em>NeurIPS</em>.
</div>
<div id="ref-raykar_ranking_2011" class="csl-entry" role="listitem">
Raykar, Vikas C, and Shipeng Yu. 2011. <span>“Ranking Annotators for Crowdsourced Labeling Tasks.”</span> In <em>NeurIPS</em>, 1809–17.
</div>
<div id="ref-rodrigues2017learning" class="csl-entry" role="listitem">
Rodrigues, Filipe, Mariana Lourenco, Bernardete Ribeiro, and Francisco C Pereira. 2017. <span>“Learning Supervised Topic Models for Classification and Regression from Crowds.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 39 (12): 2409–22.
</div>
<div id="ref-rodrigues2018deep" class="csl-entry" role="listitem">
Rodrigues, Filipe, and Francisco Pereira. 2018. <span>“Deep Learning from Crowds.”</span> In <em>AAAI</em>. Vol. 32.
</div>
<div id="ref-plantgame2016" class="csl-entry" role="listitem">
Servajean, Maximilien, Alexis Joly, Dennis Shasha, Julien Champ, and Esther Pacitti. 2016. <span>“ThePlantGame: Actively Training Human Annotators for Domain-Specific Crowdsourcing.”</span> In <em>Proceedings of the 24th ACM International Conference on Multimedia</em>, 720–21. MM ’16. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/2964284.2973820">https://doi.org/10.1145/2964284.2973820</a>.
</div>
<div id="ref-servajean2017crowdsourcing" class="csl-entry" role="listitem">
———. 2017. <span>“Crowdsourcing Thousands of Specialized Labels: A <span>Bayesian</span> Active Training Approach.”</span> <em>IEEE Transactions on Multimedia</em> 19 (6): 1376–91.
</div>
<div id="ref-sinha2018fast" class="csl-entry" role="listitem">
Sinha, Vaibhav B, Sukrut Rao, and Vineeth N Balasubramanian. 2018. <span>“Fast <span>Dawid-Skene</span>: A Fast Vote Aggregation Scheme for Sentiment Classification.”</span> <em>arXiv Preprint arXiv:1803.02781</em>.
</div>
<div id="ref-tinati2017investigation" class="csl-entry" role="listitem">
Tinati, Ramine, Markus Luczak-Roesch, Elena Simperl, and Wendy Hall. 2017. <span>“An Investigation of Player Motivations in Eyewire, a Gamified Citizen Science Project.”</span> <em>Computers in Human Behavior</em> 73: 527–40.
</div>
<div id="ref-whitehill_whose_2009" class="csl-entry" role="listitem">
Whitehill, J, T Wu, J Bergsma, J Movellan, and P Ruvolo. 2009. <span>“Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise.”</span> In <em>NeurIPS</em>. Vol. 22.
</div>
<div id="ref-YasminRomena2022ICIC" class="csl-entry" role="listitem">
Yasmin, Romena, Md Mahmudulla Hassan, Joshua T Grassel, Harika Bhogaraju, Adolfo R Escobedo, and Olac Fuentes. 2022. <span>“Improving Crowdsourcing-Based Image Classification Through Expanded Input Elicitation and Machine Learning.”</span> <em>Frontiers in Artificial Intelligence</em> 5: 848056.
</div>
<div id="ref-zhang2017mixup" class="csl-entry" role="listitem">
Zhang, Hongyi, Moustapha Cissé, Yann N. Dauphin, and David Lopez-Paz. 2018. <span>“Mixup: Beyond Empirical Risk Minimization.”</span> In <em>ICLR</em>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{lefort2023,
  author = {Lefort, Tanguy and Charlier, Benjamin and Joly, Alexis and
    Salmon, Joseph},
  publisher = {Société Française de Statistique},
  title = {Peerannot: Learning from Crowdsourced Image Datasets with
    {Python}},
  journal = {Computo},
  date = {2023-04-27},
  url = {https://computo.sfds.asso.fr/template-computo-quarto},
  doi = {xxxx},
  issn = {2824-7795},
  langid = {en},
  abstract = {Crowdsourcing is a quick and easy way to collect labels
    for large datasets, involving many workers. However, workers often
    disagree with each other. Sources of error can arise from the
    workers’ skills, but also from the intrinsic difficulty of the task.
    We present `peerannot`: a `Python` library for managing and learning
    from crowdsourced labels. Our library allows users to aggregate
    labels from common noise models or train a deep learning-based
    classifier directly from crowdsourced labels. In addition, we
    provide an identification module to easily explore the task
    difficulty of datasets and worker capabilities.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-lefort2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Lefort, Tanguy, Benjamin Charlier, Alexis Joly, and Joseph Salmon. 2023.
<span>“Peerannot: Learning from Crowdsourced Image Datasets with
Python.”</span> <em>Computo</em>, April. <a href="https://doi.org/xxxx">https://doi.org/xxxx</a>.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, function() {
      let href = xref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children.length > 2) {
          for (let i = 0; i < 2; i++) {
            container.appendChild(note.children[i].cloneNode(true));
          }
          return container.innerHTML
        } else {
          return note.innerHTML;
        }
      } else {
        return note.innerHTML;
      }
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb30" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Peerannot: learning from crowdsourced image datasets with Python"</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> ""</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Tanguy Lefort</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co">    email: tanguy.lefort@umontpellier.fr</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://tanglef.github.io</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0009-0000-6710-3221</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Name of Affiliation one</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co">        department: Statistics</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://someplace.themoon.org</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Benjamin Charlier</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">    email: benjamin.charlier@umontpellier.fr</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://imag.umontpellier.fr/~charlier/index.php?page=index&amp;lang=en</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Name of Afficiliation two</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="co">        department: Computer Science</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://someplace.themoon.org</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Alexis Joly</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a><span class="co">    email: alexis.joly@inria.fr</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a><span class="co">    url: http://www-sop.inria.fr/members/Alexis.Joly/wiki/pmwiki.php</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-2161-9940</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Name of Afficiliation two</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="co">        department: Computer Science</span></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://someplace.themoon.org</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Joseph Salmon</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="co">    email: joseph.salmon@umontpellier.fr</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a><span class="co">    url: http://josephsalmon.eu/</span></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-3181-0634</span></span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Name of Afficiliation two</span></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a><span class="co">        department: Computer Science</span></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://someplace.themoon.org</span></span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> last-modified</span></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a><span class="co">  Crowdsourcing is a quick and easy way to collect labels for large datasets, involving many workers.</span></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a><span class="co">  However, it is common for workers to disagree with each other.</span></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a><span class="co">  Sources of error can arise from the workers' skills, but also from the intrinsic difficulty of the task.</span></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a><span class="co">  We introduce peerannot, a Python library for managing and learning from crowdsourced labels.</span></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> &gt;+</span></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a><span class="co">  Crowdsourcing is a quick and easy way to collect labels for large datasets, involving many workers. However, workers often disagree with each other. Sources of error can arise from the workers' skills, but also from the intrinsic difficulty of the task. We present `peerannot`: a `Python` library for managing and learning from crowdsourced labels. Our library allows users to aggregate labels from common noise models or train a deep learning-based classifier directly from crowdsourced labels. In addition, we provide an identification module to easily explore the task difficulty of datasets and worker capabilities.</span></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> [crowdsourcing, label noise, task difficulty, worker ability]</span></span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span></span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a><span class="co">  type: article-journal</span></span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a><span class="co">  container-title: "Computo"</span></span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a><span class="co">  doi: "xxxx"</span></span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a><span class="co">  url: https://computo.sfds.asso.fr/template-computo-quarto</span></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a><span class="co">  publisher: "Société Française de Statistique"</span></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a><span class="co">  issn: "2824-7795"</span></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> computorg</span></span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> "template-computo-python"</span></span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> true # set to false once the build is running</span></span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> false # will be set to true once accepted</span></span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html: default</span></span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-pdf: default</span></span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span><span class="co">  # to remove at the end</span></span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a><span class="co">  cache: false</span></span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction: crowdsourcing in image classification</span></span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>Image datasets widely use crowdsourcing to collect labels, involving many workers that can annotate images for a small cost (or even free for instance in citizen science) and faster than using expert labeling.</span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>Many classical datasets considered in machine learning have been created with human intervention to create labels, such as CIFAR-$10$, <span class="co">[</span><span class="ot">@krizhevsky2009learning</span><span class="co">]</span>,</span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a>ImageNet <span class="co">[</span><span class="ot">@imagenet_cvpr09</span><span class="co">]</span> or <span class="co">[</span><span class="ot">@Garcin_Joly_Bonnet_Affouard_Lombardo_Chouet_Servajean_Lorieul_Salmon2021</span><span class="co">]</span> in image classification, but also COCO <span class="co">[</span><span class="ot">@cocodataset</span><span class="co">]</span>, solar photovoltaic arrays <span class="co">[</span><span class="ot">@kasmi2023crowdsourced</span><span class="co">]</span> or even macro litter <span class="co">[</span><span class="ot">@chagneux2023</span><span class="co">]</span> in image segmentation and object counting.</span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a>Crowdsourced datasets induce at least three major challenges to which we contribute with <span class="in">`peerannot`</span>:</span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>  1) *How to identify good workers in the crowd?* When multiple answers are given to a single task, looking for who to trust for which type of task becomes necessary to estimate the ground truth or later train a model with as few noise sources as possible. The module <span class="in">`identify`</span> uses different scoring metrics to create a worker and/or task evaluation.</span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>  This is particularly relevant considering the gamification of crowdsourcing experiments <span class="co">[</span><span class="ot">@plantgame2016</span><span class="co">]</span></span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a>  1) *How to aggregate multiple labels into a single label from crowdsourced tasks?* This occurs for example when dealing with a single dataset that has been labeled by multiple workers with disagreements. This is also encountered with other scoring issues such as polls, reviews, peer-grading, *etc.* In our framework this is treated with the <span class="in">`aggregate`</span> command, that given multiple labels, infers a ground truth label. From aggregated labels, a classifier can then be trained using the <span class="in">`train`</span> command.</span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>  1) *How to learn a classifier from crowdsourced datasets?* Where the first question is bound by aggregating multiple labels into a single one, this considers the case where we do not need a single label to train on, but instead train a classifier on the crowdsourced data, with the motivation to perform well on a testing set. This end-to-end vision, is common in machine learning, however, it requires the actual tasks (the images, texts, videos, *etc.*) to train on -- and in crowdsourced datasets publicly available, they are not always available. This is treated with the <span class="in">`aggregate-deep`</span> command.</span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a>The library <span class="in">`peerannot`</span> addresses these practical questions within a reproducible setting. Indeed, the complexity of experiments often leads to a lack of transparency and reproducible results for simulations and real datasets.</span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>We propose standard simulation settings with explicit implementation parameters that can be shared.</span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a>For real datasets, <span class="in">`peerannot`</span> is compatible with standard neural networks architectures from the <span class="in">`Torchvision`</span> <span class="co">[</span><span class="ot">@torchvision</span><span class="co">]</span> library and <span class="in">`Pytorch`</span> <span class="co">[</span><span class="ot">@pytorch</span><span class="co">]</span>, allowing a flexible framework with easy-to-share scripts to reproduce experiments.</span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a><span class="al">![From crowdsourced labels to training a classifier neural network, the learning pipeline using the `peerannot` library. An optional preprocessing step using the `identify` command allows us to remove worse performing workers or images that can not be classified correctly (very bad quality for example). Then, from the cleaned dataset, if we want labels we use the `aggregate` command that follows the chosen strategy. From the aggregated labels we can train a neural network classifier with the `train` command. Otherwise, we can directly train a neural network classifier that takes into account the crowdsourcing setting in its architecture using `aggregate-deep`.](./figures/strategiesbis.png)</span>{#fig-pipeline width=500}</span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a><span class="fu"># Notation and package structure</span></span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a><span class="fu">## Crowdsourcing notation</span></span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a>Let us consider the classical supervised learning classification framework. A training set $\mathcal{D}=<span class="sc">\{</span>(x_i, y_i^\star)<span class="sc">\}</span>_{i=1}^{n_{\text{task}}}$ is composed of $n_{\text{task}}$ tasks $x_i\in\mathcal{X}$ (the feature space) with (unobserved) ground truth label $y_i^\star \in <span class="co">[</span><span class="ot">K</span><span class="co">]</span>={1,\dots,K}$ one of the $K$ possible classes.</span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a>In the following, the tasks considered are generally RGB images. We use the notation $\sigma$ for the softmax function.</span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a>We use the $i$ index notation to denote the tasks dimension and the $j$ index notation for the workers in the crowdsourcing experiment.</span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a>Note that indices start at position $1$ in the equation to follow mathematical standard notation such as $<span class="co">[</span><span class="ot">K</span><span class="co">]</span>=1,\dots,K$ but it should be addressed that, as this is a <span class="in">`Python`</span> library, in the code indices start at the $0$ position.</span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>With crowdsourced data the ground truth of a task $x_i$, denoted $y_i^\star$ is unknown, and there is no single label that can be trusted as in standard supervised learning (even on the train set!).</span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a>Instead, there is a crowd of $n_{\text{worker}}$ workers from which multiple workers $(w_j)_j$ propose a label $(y_i^{(j)})_j$.</span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a>The set of workers answering the task $x_i$ is denoted by $\mathcal{A}(x_i)=<span class="sc">\{</span>j\in<span class="co">[</span><span class="ot">n_\text{worker}</span><span class="co">]</span>: w_j \text{ answered }x_i<span class="sc">\}</span>$.</span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>The cardinal $\vert \mathcal{A}(x_i)\vert$ is called the feedback effort on the task $x_i$.</span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>Note that the feedback effort can not exceed the total number of workers $n_{\text{worker}}$.</span>
<span id="cb30-101"><a href="#cb30-101" aria-hidden="true" tabindex="-1"></a>Similarly, one can adopt a worker point of view: the set of tasks answered by a worker $w_j$ is denoted $\mathcal{T}(w_j)=<span class="sc">\{</span>i\in<span class="co">[</span><span class="ot">n_\text{task}</span><span class="co">]</span>: w_j \text{ answered } x_i<span class="sc">\}</span>$.</span>
<span id="cb30-102"><a href="#cb30-102" aria-hidden="true" tabindex="-1"></a>The cardinal $\vert \mathcal{T}(w_j)\vert$ is called the workerload of $w_j$.</span>
<span id="cb30-103"><a href="#cb30-103" aria-hidden="true" tabindex="-1"></a>The final dataset can then be decomposed as:</span>
<span id="cb30-104"><a href="#cb30-104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-105"><a href="#cb30-105" aria-hidden="true" tabindex="-1"></a>\mathcal{D}_{\text{train}} := \bigcup_{i\in[n_\text{task}]} \{(x_i, (y_i^{(j)}) \text{ for }j\in\mathcal{A}(x_i))\} = \bigcup_{j\in[n_\text{worker}]} <span class="sc">\{</span>(x_i, (y_i^{(j)})) \text{ for }i \in\mathcal{T}(w_j)<span class="sc">\}</span> \enspace.</span>
<span id="cb30-106"><a href="#cb30-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-107"><a href="#cb30-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-108"><a href="#cb30-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-109"><a href="#cb30-109" aria-hidden="true" tabindex="-1"></a>In this article, we do not address the setting where workers report their self-confidence <span class="co">[</span><span class="ot">@YasminRomena2022ICIC</span><span class="co">]</span>, nor settings where workers are presented a trapping set -- *i.e* a subset of tasks where the ground truth is known to evaluate them with known labels <span class="co">[</span><span class="ot">@khattak_toward_2017</span><span class="co">]</span>.</span>
<span id="cb30-110"><a href="#cb30-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-111"><a href="#cb30-111" aria-hidden="true" tabindex="-1"></a><span class="fu">## Storing crowdsourced datasets in `peerannot`</span></span>
<span id="cb30-112"><a href="#cb30-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-113"><a href="#cb30-113" aria-hidden="true" tabindex="-1"></a>Crowdsourced datasets come in various</span>
<span id="cb30-114"><a href="#cb30-114" aria-hidden="true" tabindex="-1"></a>To store crowdsourcing datasets efficiently and in a standardized way, <span class="in">`peerannot`</span> proposes the following structure, where each dataset equals a folder:</span>
<span id="cb30-115"><a href="#cb30-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-116"><a href="#cb30-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-119"><a href="#cb30-119" aria-hidden="true" tabindex="-1"></a><span class="in">```{bash}</span></span>
<span id="cb30-120"><a href="#cb30-120" aria-hidden="true" tabindex="-1"></a><span class="ex">datasetname</span></span>
<span id="cb30-121"><a href="#cb30-121" aria-hidden="true" tabindex="-1"></a>      <span class="ex">├──</span> train</span>
<span id="cb30-122"><a href="#cb30-122" aria-hidden="true" tabindex="-1"></a>      <span class="ex">│</span>     ├── class1</span>
<span id="cb30-123"><a href="#cb30-123" aria-hidden="true" tabindex="-1"></a>      <span class="ex">│</span>     │     ├─ imagename-<span class="op">&lt;</span>key<span class="op">&gt;</span>.png</span>
<span id="cb30-124"><a href="#cb30-124" aria-hidden="true" tabindex="-1"></a>      <span class="ex">│</span>     │     ├─ ...</span>
<span id="cb30-125"><a href="#cb30-125" aria-hidden="true" tabindex="-1"></a>      <span class="ex">│</span>     │     └─ anotherimagename-<span class="op">&lt;</span>anotherkey<span class="op">&gt;</span>.png</span>
<span id="cb30-126"><a href="#cb30-126" aria-hidden="true" tabindex="-1"></a>      <span class="ex">│</span>     ├── ...</span>
<span id="cb30-127"><a href="#cb30-127" aria-hidden="true" tabindex="-1"></a>      <span class="ex">│</span>     └── classK</span>
<span id="cb30-128"><a href="#cb30-128" aria-hidden="true" tabindex="-1"></a>      <span class="ex">├──</span> val</span>
<span id="cb30-129"><a href="#cb30-129" aria-hidden="true" tabindex="-1"></a>      <span class="ex">├──</span> test</span>
<span id="cb30-130"><a href="#cb30-130" aria-hidden="true" tabindex="-1"></a>      <span class="ex">├──</span> metadata.json</span>
<span id="cb30-131"><a href="#cb30-131" aria-hidden="true" tabindex="-1"></a>      <span class="ex">└──</span> answers.json</span>
<span id="cb30-132"><a href="#cb30-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-133"><a href="#cb30-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-134"><a href="#cb30-134" aria-hidden="true" tabindex="-1"></a>The <span class="in">`answers.json`</span> file stores the different votes for each task as described in @fig-answers.</span>
<span id="cb30-135"><a href="#cb30-135" aria-hidden="true" tabindex="-1"></a>Thus, for example for an image named <span class="in">`smiley_face-1`</span>, the associated labels are stored in the <span class="in">`answers.json`</span> at the key numbered <span class="in">`1`</span>.</span>
<span id="cb30-136"><a href="#cb30-136" aria-hidden="true" tabindex="-1"></a>This key identification system allows us to track directly from the filename the crowdsourced labels without having to rely on multiple indexing files as can be traditionally proposed.</span>
<span id="cb30-137"><a href="#cb30-137" aria-hidden="true" tabindex="-1"></a>Furthermore, storing labels in a dictionary is more memory-friendly than having an array of size <span class="in">`(n_task,n_worker)`</span> and writing <span class="in">`-1`</span> when the worker $w_j$ did not see the task $x_i$ and $y_i^{(j)}$ otherwise (used in recent works such as @rodrigues2017learning).</span>
<span id="cb30-138"><a href="#cb30-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-139"><a href="#cb30-139" aria-hidden="true" tabindex="-1"></a><span class="al">![From collected labels to data storage in the `answers.json` file for a binary classification ($K=2$) on recognizing smiling faces. (left: how data is stored in `peerannot`, right: data collected)](./figures/json_answers.png)</span>{#fig-answers fig-align="center"}</span>
<span id="cb30-140"><a href="#cb30-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-141"><a href="#cb30-141" aria-hidden="true" tabindex="-1"></a>In @fig-answers, there are three tasks, $n_{\text{worker}}=4$ workers and $K=2$ classes.</span>
<span id="cb30-142"><a href="#cb30-142" aria-hidden="true" tabindex="-1"></a>If the tasks (images) are available, they must be stored as it is usual to store <span class="in">`ImageFolder`</span> datasets with <span class="in">`pytorch`</span> into a <span class="in">`train`</span>, <span class="in">`val`</span> and <span class="in">`test`</span> folder.</span>
<span id="cb30-143"><a href="#cb30-143" aria-hidden="true" tabindex="-1"></a>Each image can have its name followed by its index in the <span class="in">`answers.json`</span> file.</span>
<span id="cb30-144"><a href="#cb30-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-145"><a href="#cb30-145" aria-hidden="true" tabindex="-1"></a>Finally, a <span class="in">`metadata.json`</span> file includes relevant information related to the crowdsourcing experiment such as the number of workers, the number of tasks, *etc.*</span>
<span id="cb30-146"><a href="#cb30-146" aria-hidden="true" tabindex="-1"></a>For example, a minimal <span class="in">`metadata.json`</span> file for the toy dataset presented in @fig-answers is:</span>
<span id="cb30-147"><a href="#cb30-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-150"><a href="#cb30-150" aria-hidden="true" tabindex="-1"></a><span class="in">```{json}</span></span>
<span id="cb30-151"><a href="#cb30-151" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb30-152"><a href="#cb30-152" aria-hidden="true" tabindex="-1"></a>    <span class="st">"name"</span><span class="op">:</span> <span class="st">"toy-data"</span><span class="op">,</span></span>
<span id="cb30-153"><a href="#cb30-153" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_classes"</span><span class="op">:</span> <span class="dv">2</span><span class="op">,</span></span>
<span id="cb30-154"><a href="#cb30-154" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_workers"</span><span class="op">:</span> <span class="dv">4</span><span class="op">,</span></span>
<span id="cb30-155"><a href="#cb30-155" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_tasks"</span><span class="op">:</span> <span class="dv">3</span></span>
<span id="cb30-156"><a href="#cb30-156" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-157"><a href="#cb30-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-158"><a href="#cb30-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-159"><a href="#cb30-159" aria-hidden="true" tabindex="-1"></a>The <span class="in">`toy-data`</span> example dataset is available as example <span class="co">[</span><span class="ot">in the `peerannot` repository</span><span class="co">](https://github.com/peerannot/peerannot/tree/main/datasets/toy-data)</span>.</span>
<span id="cb30-160"><a href="#cb30-160" aria-hidden="true" tabindex="-1"></a>Classical datasets in crowdsourcing such as CIFAR-10H and LabelMe can be installed directly using <span class="in">`peerannot`</span> (an example is provided in @sec-real-datasets)</span>
<span id="cb30-161"><a href="#cb30-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-162"><a href="#cb30-162" aria-hidden="true" tabindex="-1"></a><span class="fu"># Aggregation strategies in crowdsourcing</span></span>
<span id="cb30-163"><a href="#cb30-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-164"><a href="#cb30-164" aria-hidden="true" tabindex="-1"></a>The first question we address with <span class="in">`peerannot`</span> is: *How to aggregate multiple labels into a single label from crowdsourced tasks?*</span>
<span id="cb30-165"><a href="#cb30-165" aria-hidden="true" tabindex="-1"></a>The aggregation step can lead to two types of learnable labels $\hat y_i\in\Delta_{K}$ (where $\Delta_{K}$ is the simplex of dimension $K-1$ : $\Delta_{K}=<span class="sc">\{</span>p \in <span class="co">[</span><span class="ot">K</span><span class="co">]</span>: \sum_{k=1}^K p_k = 1, p_k \geq 0 <span class="sc">\}</span>$ ) depending on the use case for each task $x_i$, $i=1,\dots,n_{\text{task}}$:</span>
<span id="cb30-166"><a href="#cb30-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-167"><a href="#cb30-167" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a **hard** label: $\hat y_i$ is a Dirac distribution, this can be encoded as a classical label in $<span class="co">[</span><span class="ot">K</span><span class="co">]</span>$,</span>
<span id="cb30-168"><a href="#cb30-168" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>a **soft** label: $\hat y_i\in\Delta_{K}$ can any probability distribution (different from a Dirac distribution). In that case, each coefficient in $\hat y_i$ represents the probability to belong to the given class.</span>
<span id="cb30-169"><a href="#cb30-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-170"><a href="#cb30-170" aria-hidden="true" tabindex="-1"></a>Learning from soft labels has been shown to improve learning performance and make the classifier learn the task ambiguity <span class="co">[</span><span class="ot">@zhang2017mixup;@peterson_human_2019;@park2022calibration</span><span class="co">]</span>.</span>
<span id="cb30-171"><a href="#cb30-171" aria-hidden="true" tabindex="-1"></a>However, crowdsourcing is often used as a stepping stone to creating a new dataset and we usually expect a classification dataset to associate a task $x_i$ to a single label and not a full probability distribution.</span>
<span id="cb30-172"><a href="#cb30-172" aria-hidden="true" tabindex="-1"></a>In this case, we recommend in practice releasing the anonymous answered labels and the aggregation strategy used to reach a consensus on a single label.</span>
<span id="cb30-173"><a href="#cb30-173" aria-hidden="true" tabindex="-1"></a>With <span class="in">`peerannot`</span>, both soft and hard labels can be produced.</span>
<span id="cb30-174"><a href="#cb30-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-175"><a href="#cb30-175" aria-hidden="true" tabindex="-1"></a>Note that when a strategy produces a soft label, a hard label can be induced by taking the mode, i.e., the class achieving the maximum probability.</span>
<span id="cb30-176"><a href="#cb30-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-177"><a href="#cb30-177" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classical models</span></span>
<span id="cb30-178"><a href="#cb30-178" aria-hidden="true" tabindex="-1"></a>We list below the most classical aggregation strategies used in crowdsourcing.</span>
<span id="cb30-179"><a href="#cb30-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-180"><a href="#cb30-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### Majority vote (MV)</span></span>
<span id="cb30-181"><a href="#cb30-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-182"><a href="#cb30-182" aria-hidden="true" tabindex="-1"></a>While the most intuitive way to create a label from multiple answers for any type of crowdsourced task would be to take the majority vote (MV), this strategy has many shortcomings <span class="co">[</span><span class="ot">@james1998majority</span><span class="co">]</span> -- there is no noise model, no worker reliability estimated, no task difficulty involved and especially no way to remove poorly performing workers. This baseline aggregation can be expressed as:</span>
<span id="cb30-183"><a href="#cb30-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-184"><a href="#cb30-184" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-185"><a href="#cb30-185" aria-hidden="true" tabindex="-1"></a>\hat y_i^{\text{MV}} = \operatornamewithlimits{argmax}_{k\in[K]} \sum_{j\in\mathcal{A}(x_i)} 1_{<span class="sc">\{</span>y_i^{(j)}=k<span class="sc">\}</span>} \enspace.</span>
<span id="cb30-186"><a href="#cb30-186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-187"><a href="#cb30-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-188"><a href="#cb30-188" aria-hidden="true" tabindex="-1"></a><span class="fu">### Naive soft (NS)</span></span>
<span id="cb30-189"><a href="#cb30-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-190"><a href="#cb30-190" aria-hidden="true" tabindex="-1"></a>One pitfall with the MV is that the label produced is hard, hence the ambiguity is discarded by construction. To remedy this, the Naive Soft (NS) labeling consists in using the empirical frequency distribution as the task label:</span>
<span id="cb30-191"><a href="#cb30-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-192"><a href="#cb30-192" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-193"><a href="#cb30-193" aria-hidden="true" tabindex="-1"></a>\hat y_i^{\text{NS}} = \bigg(\frac{1}{\vert\mathcal{A}(x_i)\vert}\sum_{j\in\mathcal{A}(x_i)} 1_{<span class="sc">\{</span>y_i^{(j)}=k<span class="sc">\}</span>} \bigg)_{j\in<span class="co">[</span><span class="ot">K</span><span class="co">]</span>} \enspace.</span>
<span id="cb30-194"><a href="#cb30-194" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-195"><a href="#cb30-195" aria-hidden="true" tabindex="-1"></a>With the NS label, we keep the ambiguity, but all workers and all tasks are put on the same level. In practice, it is known that each worker comes with their abilities, thus modeling this knowledge can produce better results.</span>
<span id="cb30-196"><a href="#cb30-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-197"><a href="#cb30-197" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dawid and Skene (DS)</span></span>
<span id="cb30-198"><a href="#cb30-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-199"><a href="#cb30-199" aria-hidden="true" tabindex="-1"></a>Going further into the aggregation, researchers began creating a noise model to take into account the workers' abilities in the aggregation.</span>
<span id="cb30-200"><a href="#cb30-200" aria-hidden="true" tabindex="-1"></a>These types of models are most often EM-based and one of the most studied <span class="co">[</span><span class="ot">@gao2013minimax</span><span class="co">]</span> and applied <span class="co">[</span><span class="ot">@servajean2017crowdsourcing;@rodrigues2018deep</span><span class="co">]</span> is the Dawid and Skene's (DS) model <span class="co">[</span><span class="ot">@dawid_maximum_1979</span><span class="co">]</span>.</span>
<span id="cb30-201"><a href="#cb30-201" aria-hidden="true" tabindex="-1"></a>Assuming the workers are answering tasks independently, this model boils down to model pairwise confusions between each possible class.</span>
<span id="cb30-202"><a href="#cb30-202" aria-hidden="true" tabindex="-1"></a>Each worker $w_j$ is assigned a confusion matrix $\pi^{(j)}\in\mathbb{R}^{K\times K}$ such that $\pi^{(j)}_{k,\ell} = \mathbb{P}(y_i^{(j)}=\ell\vert y_i^\star=k)$.</span>
<span id="cb30-203"><a href="#cb30-203" aria-hidden="true" tabindex="-1"></a>The model assumes that the probability for a task $x_i$ to have true label $y_i^\star=k$ follows a multinomial distribution with probabilities $\pi^{(j)}_{k,\bullet}$ for each worker.</span>
<span id="cb30-204"><a href="#cb30-204" aria-hidden="true" tabindex="-1"></a>Each class has a prevalence $\rho_k=\mathbb{P}(y_i^\star=k)$ to appear in the dataset.</span>
<span id="cb30-205"><a href="#cb30-205" aria-hidden="true" tabindex="-1"></a>Using the independence between workers, we obtain the following likelihood to maximize (using the EM algorithm):</span>
<span id="cb30-206"><a href="#cb30-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-207"><a href="#cb30-207" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-208"><a href="#cb30-208" aria-hidden="true" tabindex="-1"></a>\displaystyle\prod_{i\in <span class="co">[</span><span class="ot">n_{\texttt{task}}</span><span class="co">]</span>}\prod_{k \in <span class="co">[</span><span class="ot">K</span><span class="co">]</span>}\bigg<span class="co">[</span><span class="ot">\rho_k\prod_{j\in [n_{\texttt{worker}}</span><span class="co">]</span>}</span>
<span id="cb30-209"><a href="#cb30-209" aria-hidden="true" tabindex="-1"></a>    \prod_{k\in <span class="co">[</span><span class="ot">K</span><span class="co">]</span>}\big(\pi^{(j)}_{k, k}\big)^{1_{<span class="sc">\{</span>y_i^{(j)}=k<span class="sc">\}</span>}}</span>
<span id="cb30-210"><a href="#cb30-210" aria-hidden="true" tabindex="-1"></a>    \bigg]^{T_{ik}},</span>
<span id="cb30-211"><a href="#cb30-211" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-212"><a href="#cb30-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-213"><a href="#cb30-213" aria-hidden="true" tabindex="-1"></a>with $T_{i,k}=1_{<span class="sc">\{</span>y_i^{\star}=k <span class="sc">\}</span>}$. The final aggregated soft label is $\hat y_i^{\text{DS}} = T_{i,\cdot}$.</span>
<span id="cb30-214"><a href="#cb30-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-215"><a href="#cb30-215" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Bayesian [plate notation](https://en.wikipedia.org/wiki/Plate_notation) for the DS model</span><span class="co">](./figures/bayesien_plaque_ds.png)</span>{fig-align="center"}</span>
<span id="cb30-216"><a href="#cb30-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-217"><a href="#cb30-217" aria-hidden="true" tabindex="-1"></a>Many variants of the DS model have been proposed in the literature, using Dirichlet priors on the confusion matrices <span class="co">[</span><span class="ot">@passonneau-carpenter-2014-benefits</span><span class="co">]</span>, using $L$ clusters of workers <span class="co">[</span><span class="ot">@imamura2018analysis</span><span class="co">]</span> with $1\leq L\leq n_{\text{worker}}$ (DSWC) or even faster implementation that produces only hard labels <span class="co">[</span><span class="ot">@sinha2018fast</span><span class="co">]</span>.</span>
<span id="cb30-218"><a href="#cb30-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-219"><a href="#cb30-219" aria-hidden="true" tabindex="-1"></a><span class="fu">### Generative model of Labels, Abilities, and Difficulties (GLAD)</span></span>
<span id="cb30-220"><a href="#cb30-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-221"><a href="#cb30-221" aria-hidden="true" tabindex="-1"></a>Finally, we present the GLAD model <span class="co">[</span><span class="ot">@whitehill_whose_2009</span><span class="co">]</span> that not only takes into account the worker's ability, but also the task difficulty in the noise model.</span>
<span id="cb30-222"><a href="#cb30-222" aria-hidden="true" tabindex="-1"></a>Denoting $\alpha_j\in\mathbb{R}$ the worker ability (the higher the better) and $\beta_i\in\mathbb{R}^+_\star$ the task's difficulty (the higher the easier), the model noise is:</span>
<span id="cb30-223"><a href="#cb30-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-224"><a href="#cb30-224" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-225"><a href="#cb30-225" aria-hidden="true" tabindex="-1"></a>\mathbb{P}(y_i^{(j)}=y_i^\star\vert \alpha_j,\beta_i) = \frac{1}{1+\exp(-\alpha_j\beta_i)} \enspace.</span>
<span id="cb30-226"><a href="#cb30-226" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-227"><a href="#cb30-227" aria-hidden="true" tabindex="-1"></a>GLAD's model also assumes that the errors are uniform across wrong labels, thus:</span>
<span id="cb30-228"><a href="#cb30-228" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-229"><a href="#cb30-229" aria-hidden="true" tabindex="-1"></a>\forall k \in <span class="co">[</span><span class="ot">K</span><span class="co">]</span>,\ \mathbb{P}(y_i^{(j)}=k\vert y_i^\star\neq k,\alpha_j,\beta_i) = \frac{1}{K-1}\left(1-\frac{1}{1+\exp(-\alpha_j\beta_i)}\right)\enspace.</span>
<span id="cb30-230"><a href="#cb30-230" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-231"><a href="#cb30-231" aria-hidden="true" tabindex="-1"></a>The likelihood can then be optimized using an EM algorithm to recover the soft label $\hat y_i^{\text{GLAD}}$.</span>
<span id="cb30-232"><a href="#cb30-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-233"><a href="#cb30-233" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Bayesian [plate notation](https://en.wikipedia.org/wiki/Plate_notation) for the GLAD model</span><span class="co">](./figures/schema_bayesien_glad.png)</span>{fig-align="center"}</span>
<span id="cb30-234"><a href="#cb30-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-235"><a href="#cb30-235" aria-hidden="true" tabindex="-1"></a>All of these aggregation strategies -- and more -- are available in the <span class="in">`peerannot`</span> library from the <span class="in">`peerannot.models`</span> module.</span>
<span id="cb30-236"><a href="#cb30-236" aria-hidden="true" tabindex="-1"></a>Each model is a class object in its own <span class="in">`Python`</span> file. It inherits from the <span class="in">`CrowdModel`</span> template class and is defined with at least two methods:</span>
<span id="cb30-237"><a href="#cb30-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-238"><a href="#cb30-238" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`run`</span>: includes the optimization procedure to obtain needed weights (*e.g.* the EM algorithm for the DS model),</span>
<span id="cb30-239"><a href="#cb30-239" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`get_probas`</span>: returns the soft labels output for each task.</span>
<span id="cb30-240"><a href="#cb30-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-241"><a href="#cb30-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experiments and evaluation of label aggregation strategies {#sec-evaluation-aggregation}</span></span>
<span id="cb30-242"><a href="#cb30-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-243"><a href="#cb30-243" aria-hidden="true" tabindex="-1"></a>One way to evaluate the label aggregation strategies is to measure their accuracy.</span>
<span id="cb30-244"><a href="#cb30-244" aria-hidden="true" tabindex="-1"></a>This means that the underlying ground truth must be known -- or at least for a representative subset.</span>
<span id="cb30-245"><a href="#cb30-245" aria-hidden="true" tabindex="-1"></a>As the set of $n_{\text{task}}$ can be seen as a training set for a future classifier, we denote this metric $\operatornamewithlimits{AccTrain}$ on a dataset $\mathcal{D}$ for a given aggregated label $(\hat y_i)_i$ as:</span>
<span id="cb30-246"><a href="#cb30-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-247"><a href="#cb30-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-248"><a href="#cb30-248" aria-hidden="true" tabindex="-1"></a>\operatornamewithlimits{AccTrain}(\mathcal{D}) = \frac{1}{\vert \mathcal{D}\vert}\sum_{i=1}^{\vert\mathcal{D}\vert} 1_{<span class="sc">\{</span>y_i^\star=\operatornamewithlimits{argmax}_{k\in<span class="co">[</span><span class="ot">K</span><span class="co">]</span>}\hat y_i<span class="sc">\}</span>} \enspace.</span>
<span id="cb30-249"><a href="#cb30-249" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-250"><a href="#cb30-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-251"><a href="#cb30-251" aria-hidden="true" tabindex="-1"></a>In the following, we write $\operatornamewithlimits{AccTrain}$ for $\operatornamewithlimits{AccTrain}(\mathcal{D}_{\text{train}})$ as we only consider the full training set so there is no ambiguity.</span>
<span id="cb30-252"><a href="#cb30-252" aria-hidden="true" tabindex="-1"></a>While this metric is useful, in practice there are a few arguable issues:</span>
<span id="cb30-253"><a href="#cb30-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-254"><a href="#cb30-254" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the $\operatornamewithlimits{AccTrain}$ does not consider the ambiguity of the soft label, only the most probable class, whereas in some contexts ambiguity can be informative,</span>
<span id="cb30-255"><a href="#cb30-255" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>in supervised learning one objective is to identify difficult or mislabeled tasks <span class="co">[</span><span class="ot">@pleiss_identifying_2020;@lefort2022improve</span><span class="co">]</span>, pruning those tasks can easily artificially improve the $\operatornamewithlimits{AccTrain}$, but there is no guarantee over the predictive performance of a model based on the newly pruned dataset.</span>
<span id="cb30-256"><a href="#cb30-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-257"><a href="#cb30-257" aria-hidden="true" tabindex="-1"></a>We first consider classical simulation settings in the literature that can easily be created and reproduced using <span class="in">`peerannot`</span>.</span>
<span id="cb30-258"><a href="#cb30-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-259"><a href="#cb30-259" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulated independent mistakes</span></span>
<span id="cb30-260"><a href="#cb30-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-261"><a href="#cb30-261" aria-hidden="true" tabindex="-1"></a>The independent mistakes consider that each worker $w_j$ answers following a multinomial distribution with weights given at the row $y_i^\star$ of their confusion matrix $\pi^{(j)}\in\mathbb{R}^{K\times K}$. Each confusion matrix is generated diagonally dominant.</span>
<span id="cb30-262"><a href="#cb30-262" aria-hidden="true" tabindex="-1"></a>Answers are independent of one another as each matrix is generated independently and each worker answers independently of other workers.</span>
<span id="cb30-263"><a href="#cb30-263" aria-hidden="true" tabindex="-1"></a>In this setting, the DS model is expected to perform the best with enough data as we are simulating data from its assumed noise model.</span>
<span id="cb30-264"><a href="#cb30-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-265"><a href="#cb30-265" aria-hidden="true" tabindex="-1"></a>We simulate $n_{\text{task}}=200$ tasks and $n_{\text{worker}}=30$ workers with $K=5$ possible classes. Each task $x_i$ receives $\vert\mathcal{A}(x_i)\vert=10$ labels.</span>
<span id="cb30-266"><a href="#cb30-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-269"><a href="#cb30-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-270"><a href="#cb30-270" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-271"><a href="#cb30-271" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">30</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb30-272"><a href="#cb30-272" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy independent<span class="op">-</span>confusion <span class="op">\</span></span>
<span id="cb30-273"><a href="#cb30-273" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb30-274"><a href="#cb30-274" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>independent</span>
<span id="cb30-275"><a href="#cb30-275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-276"><a href="#cb30-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-277"><a href="#cb30-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-280"><a href="#cb30-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-281"><a href="#cb30-281" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-282"><a href="#cb30-282" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peerannot.helpers.helpers_visu <span class="im">import</span> feedback_effort, working_load</span>
<span id="cb30-283"><a href="#cb30-283" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb30-284"><a href="#cb30-284" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-285"><a href="#cb30-285" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> MaxNLocator</span>
<span id="cb30-286"><a href="#cb30-286" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb30-287"><a href="#cb30-287" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.ticker <span class="im">as</span> mtick</span>
<span id="cb30-288"><a href="#cb30-288" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb30-289"><a href="#cb30-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-290"><a href="#cb30-290" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb30-291"><a href="#cb30-291" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb30-292"><a href="#cb30-292" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-293"><a href="#cb30-293" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb30-294"><a href="#cb30-294" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-295"><a href="#cb30-295" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb30-296"><a href="#cb30-296" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb30-297"><a href="#cb30-297" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb30-298"><a href="#cb30-298" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-299"><a href="#cb30-299" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb30-300"><a href="#cb30-300" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb30-301"><a href="#cb30-301" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-302"><a href="#cb30-302" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb30-303"><a href="#cb30-303" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(plt.MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-304"><a href="#cb30-304" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">8</span>, <span class="dv">12</span>)</span>
<span id="cb30-305"><a href="#cb30-305" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb30-306"><a href="#cb30-306" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb30-307"><a href="#cb30-307" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-308"><a href="#cb30-308" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-309"><a href="#cb30-309" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-310"><a href="#cb30-310" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-311"><a href="#cb30-311" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-312"><a href="#cb30-312" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb30-313"><a href="#cb30-313" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-314"><a href="#cb30-314" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-315"><a href="#cb30-315" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-316"><a href="#cb30-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-317"><a href="#cb30-317" aria-hidden="true" tabindex="-1"></a>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</span>
<span id="cb30-318"><a href="#cb30-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-321"><a href="#cb30-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-322"><a href="#cb30-322" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-323"><a href="#cb30-323" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=5]"</span>, <span class="st">"DSWC[L=10]"</span>]:</span>
<span id="cb30-324"><a href="#cb30-324" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>independent<span class="op">/</span> <span class="op">-</span>s {strat}</span>
<span id="cb30-325"><a href="#cb30-325" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-326"><a href="#cb30-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-329"><a href="#cb30-329" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-330"><a href="#cb30-330" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-simu-independent</span></span>
<span id="cb30-331"><a href="#cb30-331" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: AccTrain metric on simulated independent mistakes considering classical feature-blind label aggregation strategies</span></span>
<span id="cb30-332"><a href="#cb30-332" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-333"><a href="#cb30-333" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb30-334"><a href="#cb30-334" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-335"><a href="#cb30-335" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb30-336"><a href="#cb30-336" aria-hidden="true" tabindex="-1"></a>simu_indep <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"independent"</span></span>
<span id="cb30-337"><a href="#cb30-337" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=5]"</span>: [], <span class="st">"dswc[l=10]"</span>: []}</span>
<span id="cb30-338"><a href="#cb30-338" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb30-339"><a href="#cb30-339" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_indep <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_independent-confusion_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb30-340"><a href="#cb30-340" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_indep <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb30-341"><a href="#cb30-341" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb30-342"><a href="#cb30-342" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb30-343"><a href="#cb30-343" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb30-344"><a href="#cb30-344" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb30-345"><a href="#cb30-345" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb30-346"><a href="#cb30-346" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-347"><a href="#cb30-347" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb30-348"><a href="#cb30-348" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb30-349"><a href="#cb30-349" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-350"><a href="#cb30-350" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb30-351"><a href="#cb30-351" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb30-352"><a href="#cb30-352" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb30-353"><a href="#cb30-353" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb30-354"><a href="#cb30-354" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb30-355"><a href="#cb30-355" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb30-356"><a href="#cb30-356" aria-hidden="true" tabindex="-1"></a>display(results)</span>
<span id="cb30-357"><a href="#cb30-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-358"><a href="#cb30-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-359"><a href="#cb30-359" aria-hidden="true" tabindex="-1"></a>As expected by the simulation framework, @tbl-simu-independent fits the DS model, thus leading to better accuracy to retrieve the simulated labels for the DS model. The MV aggregation does not consider any worker-ability scoring or the task's difficulty and performs the worse.</span>
<span id="cb30-360"><a href="#cb30-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-361"><a href="#cb30-361" aria-hidden="true" tabindex="-1"></a>Note that <span class="in">`peerannot`</span> can also simulate datasets with an imbalanced number of votes (*i.e.* $|\mathcal{A}(x_i)|\in <span class="co">[</span><span class="ot">\texttt{feedback}</span><span class="co">]</span>$ chosen uniformly at random). For example:</span>
<span id="cb30-362"><a href="#cb30-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-365"><a href="#cb30-365" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-366"><a href="#cb30-366" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-367"><a href="#cb30-367" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">30</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb30-368"><a href="#cb30-368" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy independent<span class="op">-</span>confusion <span class="op">\</span></span>
<span id="cb30-369"><a href="#cb30-369" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>imbalance<span class="op">-</span>votes <span class="op">\</span></span>
<span id="cb30-370"><a href="#cb30-370" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb30-371"><a href="#cb30-371" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>independent<span class="op">-</span>imbalanced<span class="op">/</span></span>
<span id="cb30-372"><a href="#cb30-372" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-373"><a href="#cb30-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-374"><a href="#cb30-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-377"><a href="#cb30-377" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-378"><a href="#cb30-378" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-379"><a href="#cb30-379" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb30-380"><a href="#cb30-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-381"><a href="#cb30-381" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent-imbalanced"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb30-382"><a href="#cb30-382" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"independent-imbalanced"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb30-383"><a href="#cb30-383" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-384"><a href="#cb30-384" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb30-385"><a href="#cb30-385" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-386"><a href="#cb30-386" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb30-387"><a href="#cb30-387" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb30-388"><a href="#cb30-388" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb30-389"><a href="#cb30-389" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-390"><a href="#cb30-390" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb30-391"><a href="#cb30-391" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb30-392"><a href="#cb30-392" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-393"><a href="#cb30-393" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb30-394"><a href="#cb30-394" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(plt.MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-395"><a href="#cb30-395" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb30-396"><a href="#cb30-396" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb30-397"><a href="#cb30-397" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-398"><a href="#cb30-398" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-399"><a href="#cb30-399" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-400"><a href="#cb30-400" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-401"><a href="#cb30-401" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-402"><a href="#cb30-402" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb30-403"><a href="#cb30-403" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-404"><a href="#cb30-404" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-405"><a href="#cb30-405" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-406"><a href="#cb30-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-407"><a href="#cb30-407" aria-hidden="true" tabindex="-1"></a>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</span>
<span id="cb30-408"><a href="#cb30-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-411"><a href="#cb30-411" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-412"><a href="#cb30-412" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-413"><a href="#cb30-413" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=5]"</span>, <span class="st">"DSWC[L=10]"</span>]:</span>
<span id="cb30-414"><a href="#cb30-414" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>independent<span class="op">-</span>imbalanced<span class="op">/</span> <span class="op">-</span>s {strat}</span>
<span id="cb30-415"><a href="#cb30-415" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-416"><a href="#cb30-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-419"><a href="#cb30-419" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-420"><a href="#cb30-420" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-simu-independent-imb</span></span>
<span id="cb30-421"><a href="#cb30-421" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: AccTrain metric on simulated independent mistakes with an imbalanced number of votes per task considering classical feature-blind label aggregation strategies</span></span>
<span id="cb30-422"><a href="#cb30-422" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-423"><a href="#cb30-423" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb30-424"><a href="#cb30-424" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-425"><a href="#cb30-425" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb30-426"><a href="#cb30-426" aria-hidden="true" tabindex="-1"></a>simu_indep <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"independent-imbalanced"</span></span>
<span id="cb30-427"><a href="#cb30-427" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=5]"</span>: [], <span class="st">"dswc[l=10]"</span>: []}</span>
<span id="cb30-428"><a href="#cb30-428" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb30-429"><a href="#cb30-429" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_indep <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_independent-confusion_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb30-430"><a href="#cb30-430" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_indep <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb30-431"><a href="#cb30-431" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb30-432"><a href="#cb30-432" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb30-433"><a href="#cb30-433" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb30-434"><a href="#cb30-434" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb30-435"><a href="#cb30-435" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb30-436"><a href="#cb30-436" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-437"><a href="#cb30-437" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb30-438"><a href="#cb30-438" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb30-439"><a href="#cb30-439" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-440"><a href="#cb30-440" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb30-441"><a href="#cb30-441" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb30-442"><a href="#cb30-442" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb30-443"><a href="#cb30-443" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb30-444"><a href="#cb30-444" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb30-445"><a href="#cb30-445" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb30-446"><a href="#cb30-446" aria-hidden="true" tabindex="-1"></a>display(results)</span>
<span id="cb30-447"><a href="#cb30-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-448"><a href="#cb30-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-449"><a href="#cb30-449" aria-hidden="true" tabindex="-1"></a>While more realistic, working with an imbalanced number of votes per task leads to disrupting orders of performance for most strategies.</span>
<span id="cb30-450"><a href="#cb30-450" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulated correlated mistakes</span></span>
<span id="cb30-451"><a href="#cb30-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-452"><a href="#cb30-452" aria-hidden="true" tabindex="-1"></a>The correlated mistakes are also known as the student-teacher setting. Consider that the crowd of workers is divided into two categories: teachers and students such that $n_{\text{teacher}} + n_{\text{student}}=n_{\text{worker}}$. Each student is randomly assigned to one teacher at the beginning of the experiment. We generate the (diagonally dominant) confusion matrices of each teacher and the students are associated with their's teacher confusion matrix. Then, they all answer independently, following a multinomial distribution with weights given at the row $y_i^\star$ of their confusion matrix $\pi^{(j)}\in\mathbb{R}^{K\times K}$.</span>
<span id="cb30-453"><a href="#cb30-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-454"><a href="#cb30-454" aria-hidden="true" tabindex="-1"></a>We simulate $n_{\text{task}}=200$ tasks and $n_{\text{worker}}=30$ with $80\%$ of students in the crowd. There are $K=5$ possible classes. Each task receives $\vert\mathcal{A}(x_i)\vert=10$ labels.</span>
<span id="cb30-455"><a href="#cb30-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-458"><a href="#cb30-458" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-459"><a href="#cb30-459" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-460"><a href="#cb30-460" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">30</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb30-461"><a href="#cb30-461" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy student<span class="op">-</span>teacher <span class="op">\</span></span>
<span id="cb30-462"><a href="#cb30-462" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>ratio <span class="fl">0.8</span> <span class="op">\</span></span>
<span id="cb30-463"><a href="#cb30-463" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback<span class="op">=</span><span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb30-464"><a href="#cb30-464" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>student_teacher</span>
<span id="cb30-465"><a href="#cb30-465" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-466"><a href="#cb30-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-467"><a href="#cb30-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-470"><a href="#cb30-470" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-471"><a href="#cb30-471" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-472"><a href="#cb30-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-473"><a href="#cb30-473" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"student_teacher"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb30-474"><a href="#cb30-474" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"student_teacher"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb30-475"><a href="#cb30-475" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-476"><a href="#cb30-476" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb30-477"><a href="#cb30-477" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-478"><a href="#cb30-478" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb30-479"><a href="#cb30-479" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb30-480"><a href="#cb30-480" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb30-481"><a href="#cb30-481" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-482"><a href="#cb30-482" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb30-483"><a href="#cb30-483" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb30-484"><a href="#cb30-484" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-485"><a href="#cb30-485" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb30-486"><a href="#cb30-486" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(plt.MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-487"><a href="#cb30-487" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">8</span>, <span class="dv">12</span>)</span>
<span id="cb30-488"><a href="#cb30-488" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb30-489"><a href="#cb30-489" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb30-490"><a href="#cb30-490" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-491"><a href="#cb30-491" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-492"><a href="#cb30-492" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-493"><a href="#cb30-493" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-494"><a href="#cb30-494" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-495"><a href="#cb30-495" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb30-496"><a href="#cb30-496" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-497"><a href="#cb30-497" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-498"><a href="#cb30-498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-499"><a href="#cb30-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-500"><a href="#cb30-500" aria-hidden="true" tabindex="-1"></a>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</span>
<span id="cb30-501"><a href="#cb30-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-504"><a href="#cb30-504" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-505"><a href="#cb30-505" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-506"><a href="#cb30-506" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=5]"</span>, <span class="st">"DSWC[L=10]"</span>]:</span>
<span id="cb30-507"><a href="#cb30-507" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>student_teacher<span class="op">/</span> <span class="op">-</span>s {strat}</span>
<span id="cb30-508"><a href="#cb30-508" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-509"><a href="#cb30-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-512"><a href="#cb30-512" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-513"><a href="#cb30-513" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-simu-corr</span></span>
<span id="cb30-514"><a href="#cb30-514" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: AccTrain metric on simulated correlated mistakes considering classical feature-blind label aggregation strategies</span></span>
<span id="cb30-515"><a href="#cb30-515" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-516"><a href="#cb30-516" aria-hidden="true" tabindex="-1"></a>simu_corr <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"student_teacher"</span></span>
<span id="cb30-517"><a href="#cb30-517" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=5]"</span>: [], <span class="st">"dswc[l=10]"</span>: []}</span>
<span id="cb30-518"><a href="#cb30-518" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb30-519"><a href="#cb30-519" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_corr <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_student-teacher_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb30-520"><a href="#cb30-520" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_corr <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb30-521"><a href="#cb30-521" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb30-522"><a href="#cb30-522" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb30-523"><a href="#cb30-523" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb30-524"><a href="#cb30-524" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb30-525"><a href="#cb30-525" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb30-526"><a href="#cb30-526" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-527"><a href="#cb30-527" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb30-528"><a href="#cb30-528" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb30-529"><a href="#cb30-529" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-530"><a href="#cb30-530" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb30-531"><a href="#cb30-531" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb30-532"><a href="#cb30-532" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb30-533"><a href="#cb30-533" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb30-534"><a href="#cb30-534" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb30-535"><a href="#cb30-535" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb30-536"><a href="#cb30-536" aria-hidden="true" tabindex="-1"></a>display(results)</span>
<span id="cb30-537"><a href="#cb30-537" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-538"><a href="#cb30-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-539"><a href="#cb30-539" aria-hidden="true" tabindex="-1"></a>With @tbl-simu-corr, we see that with correlated data ($24$ students and $6$ teachers), using $5$ confusion matrices with DSWC<span class="co">[</span><span class="ot">L=5</span><span class="co">]</span> outperforms the vanilla DS strategy that does not consider the correlations.</span>
<span id="cb30-540"><a href="#cb30-540" aria-hidden="true" tabindex="-1"></a>And the best-performing method here estimates only $10$ confusion matrices (instead of $30$ for the vanilla DS model).</span>
<span id="cb30-541"><a href="#cb30-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-542"><a href="#cb30-542" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulated mistakes with discrete difficulty levels on tasks</span></span>
<span id="cb30-543"><a href="#cb30-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-544"><a href="#cb30-544" aria-hidden="true" tabindex="-1"></a>For the final simulation setting, we consider the discrete difficulty presented in @whitehill_whose_2009.</span>
<span id="cb30-545"><a href="#cb30-545" aria-hidden="true" tabindex="-1"></a>Contrary to other simulations, we here consider that workers belong to two levels of abilities: \texttt{good} or \texttt{bad}, and tasks have two levels of difficulty: \texttt{easy} or \texttt{hard}.</span>
<span id="cb30-546"><a href="#cb30-546" aria-hidden="true" tabindex="-1"></a>The keyword <span class="in">`ratio-diff`</span> indicates the prevalence of each level of difficulty, it is defined as the ratio of \texttt{easy} tasks over \texttt{hard} tasks:</span>
<span id="cb30-547"><a href="#cb30-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-548"><a href="#cb30-548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-549"><a href="#cb30-549" aria-hidden="true" tabindex="-1"></a>\texttt{ratio-diff} = \frac{\mathbb{P}(\texttt{easy})}{\mathbb{P}(\texttt{hard})} \text{ with } \mathbb{P}(\texttt{easy}) +\mathbb{P}(\texttt{hard}) = 1 \enspace.</span>
<span id="cb30-550"><a href="#cb30-550" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-551"><a href="#cb30-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-552"><a href="#cb30-552" aria-hidden="true" tabindex="-1"></a>Difficulties are then drawn <span class="co">[</span><span class="ot">following at random</span><span class="co">](https://peerannot.github.io/datasets/simulate_discrete_difficulty/)</span>.</span>
<span id="cb30-553"><a href="#cb30-553" aria-hidden="true" tabindex="-1"></a>Tasks that are \texttt{easy} are answered correctly by every worker.</span>
<span id="cb30-554"><a href="#cb30-554" aria-hidden="true" tabindex="-1"></a>Tasks that are \texttt{hard} are answered following the confusion matrix assigned to each worker.</span>
<span id="cb30-555"><a href="#cb30-555" aria-hidden="true" tabindex="-1"></a>Each worker then answers independently to the presented tasks.</span>
<span id="cb30-556"><a href="#cb30-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-557"><a href="#cb30-557" aria-hidden="true" tabindex="-1"></a>We simulate $n_{\text{task}}=500$ tasks and $n_{\text{worker}}=100$ with $35\%$ of good workers in the crowd and $50\%$ of easy tasks. There are $K=5$ possible classes. Each task receives $\vert\mathcal{A}(x_i)\vert=10$ labels.</span>
<span id="cb30-558"><a href="#cb30-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-561"><a href="#cb30-561" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-562"><a href="#cb30-562" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-563"><a href="#cb30-563" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot simulate <span class="op">--</span>n<span class="op">-</span>worker<span class="op">=</span><span class="dv">100</span> <span class="op">--</span>n<span class="op">-</span>task<span class="op">=</span><span class="dv">200</span>  <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">5</span> <span class="op">\</span></span>
<span id="cb30-564"><a href="#cb30-564" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>strategy discrete<span class="op">-</span>difficulty <span class="op">\</span></span>
<span id="cb30-565"><a href="#cb30-565" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>ratio <span class="fl">0.35</span> <span class="op">--</span>ratio<span class="op">-</span>diff <span class="dv">1</span> <span class="op">\</span></span>
<span id="cb30-566"><a href="#cb30-566" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>feedback <span class="dv">10</span> <span class="op">--</span>seed <span class="dv">0</span> <span class="op">\</span></span>
<span id="cb30-567"><a href="#cb30-567" aria-hidden="true" tabindex="-1"></a>                     <span class="op">--</span>folder .<span class="op">/</span>simus<span class="op">/</span>discrete_difficulty</span>
<span id="cb30-568"><a href="#cb30-568" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-569"><a href="#cb30-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-570"><a href="#cb30-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-573"><a href="#cb30-573" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-574"><a href="#cb30-574" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-575"><a href="#cb30-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-576"><a href="#cb30-576" aria-hidden="true" tabindex="-1"></a>votes_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"discrete_difficulty"</span> <span class="op">/</span> <span class="st">"answers.json"</span></span>
<span id="cb30-577"><a href="#cb30-577" aria-hidden="true" tabindex="-1"></a>metadata_path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"simus"</span> <span class="op">/</span> <span class="st">"discrete_difficulty"</span> <span class="op">/</span> <span class="st">"metadata.json"</span></span>
<span id="cb30-578"><a href="#cb30-578" aria-hidden="true" tabindex="-1"></a>efforts <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-579"><a href="#cb30-579" aria-hidden="true" tabindex="-1"></a>workerload <span class="op">=</span> working_load(votes_path, metadata_path)</span>
<span id="cb30-580"><a href="#cb30-580" aria-hidden="true" tabindex="-1"></a>feedback <span class="op">=</span> feedback_effort(votes_path)</span>
<span id="cb30-581"><a href="#cb30-581" aria-hidden="true" tabindex="-1"></a>nbins <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb30-582"><a href="#cb30-582" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">4</span>))</span>
<span id="cb30-583"><a href="#cb30-583" aria-hidden="true" tabindex="-1"></a>sns.histplot(workerload, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb30-584"><a href="#cb30-584" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-585"><a href="#cb30-585" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{T}</span><span class="vs">(w_j)\vert$"</span>)</span>
<span id="cb30-586"><a href="#cb30-586" aria-hidden="true" tabindex="-1"></a>sns.histplot(feedback, stat<span class="op">=</span><span class="st">"percent"</span>, bins<span class="op">=</span>nbins, shrink<span class="op">=</span><span class="dv">1</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb30-587"><a href="#cb30-587" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].yaxis.set_major_formatter(mtick.PercentFormatter(decimals<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb30-588"><a href="#cb30-588" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$\vert\mathcal</span><span class="sc">{A}</span><span class="vs">(x_i)\vert$"</span>)</span>
<span id="cb30-589"><a href="#cb30-589" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">8</span>, <span class="dv">12</span>)</span>
<span id="cb30-590"><a href="#cb30-590" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].xaxis.set_major_locator(MaxNLocator(integer<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb30-591"><a href="#cb30-591" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb30-592"><a href="#cb30-592" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_major_locator(MaxNLocator(<span class="dv">3</span>))</span>
<span id="cb30-593"><a href="#cb30-593" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-594"><a href="#cb30-594" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.label.set_size(<span class="dv">15</span>)</span>
<span id="cb30-595"><a href="#cb30-595" aria-hidden="true" tabindex="-1"></a>  ax[i].xaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-596"><a href="#cb30-596" aria-hidden="true" tabindex="-1"></a>  ax[i].yaxis.set_tick_params(labelsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb30-597"><a href="#cb30-597" aria-hidden="true" tabindex="-1"></a>  ax[i].title.set_size(<span class="dv">18</span>)</span>
<span id="cb30-598"><a href="#cb30-598" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb30-599"><a href="#cb30-599" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-600"><a href="#cb30-600" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-601"><a href="#cb30-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-602"><a href="#cb30-602" aria-hidden="true" tabindex="-1"></a>With the obtained answers, we can look at the aforementioned aggregation strategies performance:</span>
<span id="cb30-603"><a href="#cb30-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-606"><a href="#cb30-606" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-607"><a href="#cb30-607" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-608"><a href="#cb30-608" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strat <span class="kw">in</span> [<span class="st">"MV"</span>, <span class="st">"NaiveSoft"</span>, <span class="st">"DS"</span>, <span class="st">"GLAD"</span>, <span class="st">"DSWC[L=2]"</span>, <span class="st">"DSWC[L=5]"</span>]:</span>
<span id="cb30-609"><a href="#cb30-609" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot aggregate .<span class="op">/</span>simus<span class="op">/</span>discrete_difficulty<span class="op">/</span> <span class="op">-</span>s {strat}</span>
<span id="cb30-610"><a href="#cb30-610" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-613"><a href="#cb30-613" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-614"><a href="#cb30-614" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-simu-discrete-diff</span></span>
<span id="cb30-615"><a href="#cb30-615" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: AccTrain metric on simulated mistakes when tasks are associated a difficulty level considering classical feature-blind label aggregation strategies</span></span>
<span id="cb30-616"><a href="#cb30-616" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-617"><a href="#cb30-617" aria-hidden="true" tabindex="-1"></a>simu_corr <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">'simus'</span> <span class="op">/</span> <span class="st">"discrete_difficulty"</span></span>
<span id="cb30-618"><a href="#cb30-618" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">"mv"</span>: [], <span class="st">"naivesoft"</span>: [], <span class="st">"glad"</span>: [], <span class="st">"ds"</span>: [], <span class="st">"dswc[l=2]"</span>: [], <span class="st">"dswc[l=5]"</span>: []}</span>
<span id="cb30-619"><a href="#cb30-619" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> strategy <span class="kw">in</span> results.keys():</span>
<span id="cb30-620"><a href="#cb30-620" aria-hidden="true" tabindex="-1"></a>  path_labels <span class="op">=</span> simu_corr <span class="op">/</span> <span class="st">"labels"</span> <span class="op">/</span> <span class="ss">f"labels_discrete-difficulty_</span><span class="sc">{</span>strategy<span class="sc">}</span><span class="ss">.npy"</span></span>
<span id="cb30-621"><a href="#cb30-621" aria-hidden="true" tabindex="-1"></a>  ground_truth <span class="op">=</span> np.load(simu_corr <span class="op">/</span> <span class="st">"ground_truth.npy"</span>)</span>
<span id="cb30-622"><a href="#cb30-622" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> np.load(path_labels)</span>
<span id="cb30-623"><a href="#cb30-623" aria-hidden="true" tabindex="-1"></a>  acc <span class="op">=</span> (</span>
<span id="cb30-624"><a href="#cb30-624" aria-hidden="true" tabindex="-1"></a>          np.mean(labels <span class="op">==</span> ground_truth)</span>
<span id="cb30-625"><a href="#cb30-625" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> labels.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb30-626"><a href="#cb30-626" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> np.mean(</span>
<span id="cb30-627"><a href="#cb30-627" aria-hidden="true" tabindex="-1"></a>              np.argmax(labels, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-628"><a href="#cb30-628" aria-hidden="true" tabindex="-1"></a>              <span class="op">==</span> ground_truth</span>
<span id="cb30-629"><a href="#cb30-629" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb30-630"><a href="#cb30-630" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-631"><a href="#cb30-631" aria-hidden="true" tabindex="-1"></a>  results[strategy].append(acc)</span>
<span id="cb30-632"><a href="#cb30-632" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="st">'AccTrain'</span>])</span>
<span id="cb30-633"><a href="#cb30-633" aria-hidden="true" tabindex="-1"></a>results.columns <span class="op">=</span> <span class="bu">map</span>(<span class="bu">str</span>.upper, results.columns)</span>
<span id="cb30-634"><a href="#cb30-634" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.style.set_table_styles([<span class="bu">dict</span>(selector<span class="op">=</span><span class="st">'th'</span>, props<span class="op">=</span>[(<span class="st">'text-align'</span>, <span class="st">'center'</span>)])])</span>
<span id="cb30-635"><a href="#cb30-635" aria-hidden="true" tabindex="-1"></a>results.set_properties(<span class="op">**</span>{<span class="st">'text-align'</span>: <span class="st">'center'</span>})</span>
<span id="cb30-636"><a href="#cb30-636" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb30-637"><a href="#cb30-637" aria-hidden="true" tabindex="-1"></a>display(results)</span>
<span id="cb30-638"><a href="#cb30-638" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-639"><a href="#cb30-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-640"><a href="#cb30-640" aria-hidden="true" tabindex="-1"></a>Finally, in this setting involving task difficulty coefficients, the only strategy that involves a latent variable for the task difficulty, knowing GLAD, outperforms the other strategies (see @tbl-simu-discrete-diff). Note that in this case, creating clusters of answers leads to worse decisions than an MV aggregation.</span>
<span id="cb30-641"><a href="#cb30-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-642"><a href="#cb30-642" aria-hidden="true" tabindex="-1"></a>To summarize our simulations, we see that depending on workers answering strategies, different latent variable models perform best.</span>
<span id="cb30-643"><a href="#cb30-643" aria-hidden="true" tabindex="-1"></a>However, these are unknown outside of a simulation framework, thus if we want to obtain labels from multiple responses, we need to investigate multiple models.</span>
<span id="cb30-644"><a href="#cb30-644" aria-hidden="true" tabindex="-1"></a>This can be done easily with <span class="in">`peerannot`</span> as we demonstrated using the <span class="in">`aggregate`</span> module.</span>
<span id="cb30-645"><a href="#cb30-645" aria-hidden="true" tabindex="-1"></a>However, one might not want to generate a label, simply learn a classifier to predict labels on unseen data. This leads us to another module part of <span class="in">`peerannot`</span>.</span>
<span id="cb30-646"><a href="#cb30-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-647"><a href="#cb30-647" aria-hidden="true" tabindex="-1"></a><span class="fu"># Learning from crowdsourced tasks</span></span>
<span id="cb30-648"><a href="#cb30-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-649"><a href="#cb30-649" aria-hidden="true" tabindex="-1"></a>Most often, tasks are crowdsourced to create a large training set as modern machine learning models require more and more data.</span>
<span id="cb30-650"><a href="#cb30-650" aria-hidden="true" tabindex="-1"></a>The aggregation step then simply becomes the first step in the complete learning pipeline.</span>
<span id="cb30-651"><a href="#cb30-651" aria-hidden="true" tabindex="-1"></a>However, instead of aggregating labels, modern neural networks let us directly train a classifier from multiple noisy labels.</span>
<span id="cb30-652"><a href="#cb30-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-653"><a href="#cb30-653" aria-hidden="true" tabindex="-1"></a><span class="fu">## Classical models</span></span>
<span id="cb30-654"><a href="#cb30-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-655"><a href="#cb30-655" aria-hidden="true" tabindex="-1"></a>In recent years, directly learning a classifier from noisy labels was introduced.</span>
<span id="cb30-656"><a href="#cb30-656" aria-hidden="true" tabindex="-1"></a>Two of the most used models: CrowdLayer <span class="co">[</span><span class="ot">@rodrigues2018deep</span><span class="co">]</span> and CoNAL <span class="co">[</span><span class="ot">@chu2021learning</span><span class="co">]</span>, are directly available in <span class="in">`peerannot`</span>.</span>
<span id="cb30-657"><a href="#cb30-657" aria-hidden="true" tabindex="-1"></a>These two learning strategies directly incorporate a DS-based noise model in the neural network's architecture.</span>
<span id="cb30-658"><a href="#cb30-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-659"><a href="#cb30-659" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">CrowdLayer</span><span class="co">](https://github.com/peerannot/peerannot/blob/main/peerannot/models/agg_deep/Crowdlayer.py)</span> trains a classifier with noisy labels as follows.</span>
<span id="cb30-660"><a href="#cb30-660" aria-hidden="true" tabindex="-1"></a>Let the scores (logits) output of a given classifier neural network $\mathcal{C}$ be $z_i=\mathcal{C}(x_i)$.</span>
<span id="cb30-661"><a href="#cb30-661" aria-hidden="true" tabindex="-1"></a>Then CrowdLayer adds as a last layer $\pi\in\mathbb{R}^{n_{\text{worker}}\times K\times K}$, the tensor of all $\pi^{(j)}$s such that the crossentropy loss $(\mathrm{CE})$ is adapted to the crowdsourcing setting into $\mathcal{L}_{CE}^{\text{CrowdLayer}}$ and computed as:</span>
<span id="cb30-662"><a href="#cb30-662" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-663"><a href="#cb30-663" aria-hidden="true" tabindex="-1"></a>\mathcal{L}_{CE}^{\text{CrowdLayer}}(x_i) = \sum_{j\in\mathcal{A}(x_i)} \mathrm{CE}(\sigma\left(\pi^{(j)}\sigma\big(z_i\big)\right), y_i^{(j)}) \enspace,</span>
<span id="cb30-664"><a href="#cb30-664" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-665"><a href="#cb30-665" aria-hidden="true" tabindex="-1"></a>where the classical crossentropy loss for two distribution $u,v \in\Delta_{K}$ is defined as $\mathrm{CE}(u, v) = \sum_{k\in<span class="co">[</span><span class="ot">K</span><span class="co">]</span>} u_k\log(v_k)$.</span>
<span id="cb30-666"><a href="#cb30-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-667"><a href="#cb30-667" aria-hidden="true" tabindex="-1"></a>The confusion matrices are incorporated as is into the network architecture as a new layer to transform the output probabilities to match each worker's answer.</span>
<span id="cb30-668"><a href="#cb30-668" aria-hidden="true" tabindex="-1"></a>However, for some datasets, it was noticed that global confusion occurs between the proposed classes.</span>
<span id="cb30-669"><a href="#cb30-669" aria-hidden="true" tabindex="-1"></a>It is the case for example in the LabelMe dataset <span class="co">[</span><span class="ot">@rodrigues2017learning</span><span class="co">]</span> where classes overlap.</span>
<span id="cb30-670"><a href="#cb30-670" aria-hidden="true" tabindex="-1"></a>In this case, @chu2021learning proposed to extend the CrowdLayer model by not only modeling the worker confusion matrices; but also a global confusion matrix $\pi^g\in\mathbb{R}^{K\times K}$.</span>
<span id="cb30-671"><a href="#cb30-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-672"><a href="#cb30-672" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ![Bayesian [plate notation](https://en.wikipedia.org/wiki/Plate_notation) for CoNAL model. Each worker is assigned a confusion matrix $\pi^{(j)}$. A global confusion matrix $\pi^g$ is shared between workers. A tradeoff between the global confusion and the local one is applied.](./figures/schema_bayesien_conal.png){#fig-conal fig-align="center"} --&gt;</span></span>
<span id="cb30-673"><a href="#cb30-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-674"><a href="#cb30-674" aria-hidden="true" tabindex="-1"></a>Given the output $z_i=\mathcal{C}(x_i)\in\mathbb{R}^K$ of a given classifier and task, <span class="co">[</span><span class="ot">CoNAL</span><span class="co">](https://github.com/peerannot/peerannot/blob/main/peerannot/models/agg_deep/CoNAL.py)</span></span>
<span id="cb30-675"><a href="#cb30-675" aria-hidden="true" tabindex="-1"></a>interpolates between the local confusion $\pi^{(j)}z_i$ and the global one $\pi^gz_i$.</span>
<span id="cb30-676"><a href="#cb30-676" aria-hidden="true" tabindex="-1"></a>The loss function is computed as follows:</span>
<span id="cb30-677"><a href="#cb30-677" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-678"><a href="#cb30-678" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb30-679"><a href="#cb30-679" aria-hidden="true" tabindex="-1"></a>&amp;\mathcal{L}_{CE}^{\text{CoNAL}}(x_i) = \sum_{j\in\mathcal{A}(x_i)} \mathrm{CE}(h_i^{(j)}, y_i^{(j)}) \enspace, <span class="sc">\\</span></span>
<span id="cb30-680"><a href="#cb30-680" aria-hidden="true" tabindex="-1"></a>&amp;\text{with } h_i^{(j)} = \sigma\left(\big(\omega_i^{(j)} \pi^g + (1-\omega_i^{(j)})\pi^{(j)}\big)z_i\right) \enspace.</span>
<span id="cb30-681"><a href="#cb30-681" aria-hidden="true" tabindex="-1"></a>\end{aligned} \</span>
<span id="cb30-682"><a href="#cb30-682" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb30-683"><a href="#cb30-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-684"><a href="#cb30-684" aria-hidden="true" tabindex="-1"></a>The interpolation weight $\omega_i^{(j)}$ is unobservable in practice.</span>
<span id="cb30-685"><a href="#cb30-685" aria-hidden="true" tabindex="-1"></a>So, to compute $h_i^{(j)}$, the weight is obtained through an auxiliary network.</span>
<span id="cb30-686"><a href="#cb30-686" aria-hidden="true" tabindex="-1"></a>This network takes in input the image and worker information and outputs a task-related vector $v_i$ and a worker-related vector $u_j$ of the same dimension.</span>
<span id="cb30-687"><a href="#cb30-687" aria-hidden="true" tabindex="-1"></a>Finally, $w_i^{(j)}=(1+\exp(- u_j^\top v_i))^{-1}$.</span>
<span id="cb30-688"><a href="#cb30-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-689"><a href="#cb30-689" aria-hidden="true" tabindex="-1"></a>Both CrowdLayer and CoNAL model worker confusions directly in the classifier's weights to learn from the noisy collected labels and are available in <span class="in">`peerannot`</span> as we will see in the following.</span>
<span id="cb30-690"><a href="#cb30-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-691"><a href="#cb30-691" aria-hidden="true" tabindex="-1"></a><span class="fu">## Prediction error when learning from crowdsourced tasks</span></span>
<span id="cb30-692"><a href="#cb30-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-693"><a href="#cb30-693" aria-hidden="true" tabindex="-1"></a>The $\mathrm{AccTrain}$ metric presented in @sec-evaluation-aggregation might no longer be of interest when training a classifier. Classical error measurements involve a test dataset to estimate the generalization error.</span>
<span id="cb30-694"><a href="#cb30-694" aria-hidden="true" tabindex="-1"></a>To do so, we present hereafter two error metrics. Assuming we trained our classifier $f_\theta$ on a training set:</span>
<span id="cb30-695"><a href="#cb30-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-696"><a href="#cb30-696" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>the test accuracy is computed as $\frac{1}{n_{\text{test}}}\sum_{i=1}^{n_{\text{test}}}1_{\{y_i^\star = \widehat{f_\theta(x_i)}<span class="sc">\}</span>}$</span>
<span id="cb30-697"><a href="#cb30-697" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>the expected calibration error <span class="co">[</span><span class="ot">@guo_calibration_2017</span><span class="co">]</span> over $M$ equally spaced bins $I_1,\dots,I_M$, computed as:</span>
<span id="cb30-698"><a href="#cb30-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-699"><a href="#cb30-699" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb30-700"><a href="#cb30-700" aria-hidden="true" tabindex="-1"></a>\mathrm{ECE} = \sum_{m=1}^M \frac{|B_m|}{n_{\text{task}}}|\mathrm{acc}(B_m)</span>
<span id="cb30-701"><a href="#cb30-701" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\mathrm{conf}(B_m)|\enspace,</span>
<span id="cb30-702"><a href="#cb30-702" aria-hidden="true" tabindex="-1"></a> $$</span>
<span id="cb30-703"><a href="#cb30-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-704"><a href="#cb30-704" aria-hidden="true" tabindex="-1"></a>with $B_m=<span class="sc">\{</span>x_i| \mathcal{C}(x_i)_{<span class="co">[</span><span class="ot">1</span><span class="co">]</span>}\in I_m<span class="sc">\}</span>$ the tasks with predicted probability in the $m$-th bin, $\mathrm{acc}(B_m)$ the accuracy of the network for the samples in $B_m$ and $\mathrm{conf}(B_m)$ the associated empirical confidence.</span>
<span id="cb30-705"><a href="#cb30-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-706"><a href="#cb30-706" aria-hidden="true" tabindex="-1"></a>The accuracy represents how well the classifier generalizes, the expected calibration error (ECE) quantifies the deviation between the accuracy and the confidence of the classifier. Modern neural networks are known to often be overconfident in their predictions <span class="co">[</span><span class="ot">@guo_calibration_2017</span><span class="co">]</span>. However, it has also been remarked that training on crowdsourced data, depending on the strategy, mitigates this confidence issue. That is why we propose to compare them both in our coming experiments.</span>
<span id="cb30-707"><a href="#cb30-707" aria-hidden="true" tabindex="-1"></a>Note that the ECE error estimator is known to be biased <span class="co">[</span><span class="ot">@gruber2022better</span><span class="co">]</span>.</span>
<span id="cb30-708"><a href="#cb30-708" aria-hidden="true" tabindex="-1"></a>Smaller training sets are known to have a higher ECE estimation error.</span>
<span id="cb30-709"><a href="#cb30-709" aria-hidden="true" tabindex="-1"></a>And in the crowdsourcing setting, openly available datasets are often quite small.</span>
<span id="cb30-710"><a href="#cb30-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-711"><a href="#cb30-711" aria-hidden="true" tabindex="-1"></a><span class="fu">## Use case with `peerannot` on real datasets {#sec-real-datasets}</span></span>
<span id="cb30-712"><a href="#cb30-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-713"><a href="#cb30-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-714"><a href="#cb30-714" aria-hidden="true" tabindex="-1"></a>Few real crowdsourcing experiments have been released publicly.</span>
<span id="cb30-715"><a href="#cb30-715" aria-hidden="true" tabindex="-1"></a>Among the available ones, CIFAR-10H <span class="co">[</span><span class="ot">@peterson_human_2019</span><span class="co">]</span> is one of the largest with $10 000$ tasks labeled by workers (the testing set of CIFAR-10).</span>
<span id="cb30-716"><a href="#cb30-716" aria-hidden="true" tabindex="-1"></a>The main limitation of CIFAR-10H is that there are few disagreements between workers and a simple majority voting already leads to a near-perfect $\mathrm{AccTrain}$ error.</span>
<span id="cb30-717"><a href="#cb30-717" aria-hidden="true" tabindex="-1"></a>Hence, comparing the impact of aggregation and end-to-end strategies might not be relevant <span class="co">[</span><span class="ot">@peterson_human_2019;@aitchison2020statistical</span><span class="co">]</span>, it is however a good benchmark for task difficulty identification and worker evaluation scoring</span>
<span id="cb30-718"><a href="#cb30-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-719"><a href="#cb30-719" aria-hidden="true" tabindex="-1"></a>The LabelMe dataset was extracted from crowdsourcing segmentation experiments and a subset of $K=8$ classes was released in @rodrigues2017learning.</span>
<span id="cb30-720"><a href="#cb30-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-721"><a href="#cb30-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-722"><a href="#cb30-722" aria-hidden="true" tabindex="-1"></a>To install these datasets, we run the <span class="in">`install`</span> command from <span class="in">`peerannot`</span>:</span>
<span id="cb30-725"><a href="#cb30-725" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-726"><a href="#cb30-726" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-727"><a href="#cb30-727" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb30-728"><a href="#cb30-728" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot install .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span>labelme.py</span>
<span id="cb30-729"><a href="#cb30-729" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot install .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span>cifar10h.py</span>
<span id="cb30-730"><a href="#cb30-730" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-731"><a href="#cb30-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-732"><a href="#cb30-732" aria-hidden="true" tabindex="-1"></a>Let us use <span class="in">`peerannot`</span> to train a Resnet34 on the LabelMe dataset for:</span>
<span id="cb30-733"><a href="#cb30-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-734"><a href="#cb30-734" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>aggregation strategies: MV, NS, DS, GLAD,</span>
<span id="cb30-735"><a href="#cb30-735" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>end-to-end strategies: CrowdLayer and CoNAL.</span>
<span id="cb30-736"><a href="#cb30-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-737"><a href="#cb30-737" aria-hidden="true" tabindex="-1"></a>As we can see, CoNAL strategy performs best.</span>
<span id="cb30-738"><a href="#cb30-738" aria-hidden="true" tabindex="-1"></a>In this case, it is expected behavior as CoNAL was created for the LabelMe dataset.</span>
<span id="cb30-739"><a href="#cb30-739" aria-hidden="true" tabindex="-1"></a>However, using <span class="in">`peerannot`</span> we can look into **why modeling common confusion returns better results with this dataset**.</span>
<span id="cb30-740"><a href="#cb30-740" aria-hidden="true" tabindex="-1"></a>To do so, we can explore the datasets from two points of view: worker-wise or task-wise.</span>
<span id="cb30-741"><a href="#cb30-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-742"><a href="#cb30-742" aria-hidden="true" tabindex="-1"></a><span class="fu"># Exploring crowdsourced datasets</span></span>
<span id="cb30-743"><a href="#cb30-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-744"><a href="#cb30-744" aria-hidden="true" tabindex="-1"></a>If a dataset requires citizen knowledge to be labeled, it is because expert knowledge is long and costly to obtain. In the era of big data, where datasets are built using web scraping (or using a platform like <span class="co">[</span><span class="ot">Amazon Mechanical Turk</span><span class="co">](https://www.mturk.com/)</span>), citizen science is popular as it is an easy way to produce many labels.</span>
<span id="cb30-745"><a href="#cb30-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-746"><a href="#cb30-746" aria-hidden="true" tabindex="-1"></a>However, mistakes and confusions happen during these experiments.</span>
<span id="cb30-747"><a href="#cb30-747" aria-hidden="true" tabindex="-1"></a>Sometimes involuntarily (*e.g.* because the task is too hard or the worker is unable to differentiate between two classes) and sometimes not (*e.g.* the worker is a spammer).</span>
<span id="cb30-748"><a href="#cb30-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-749"><a href="#cb30-749" aria-hidden="true" tabindex="-1"></a>Underlying all the learning models and aggregation strategies, the cornerstone of crowdsourcing is evaluating the trust we put in each worker depending on the presented task. And with the gamification of crowdsourcing <span class="co">[</span><span class="ot">@plantgame2016;@tinati2017investigation</span><span class="co">]</span>, it has become essential to find scoring metrics both for workers and tasks to keep citizens in the loop so to speak.</span>
<span id="cb30-750"><a href="#cb30-750" aria-hidden="true" tabindex="-1"></a>This is the purpose of the identification module in <span class="in">`peerannot`</span></span>
<span id="cb30-751"><a href="#cb30-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-752"><a href="#cb30-752" aria-hidden="true" tabindex="-1"></a>Our test cases are both the CIFAR-10H dataset and the LabelMe dataset to compare the worker and task evaluation depending on the number of votes collected.</span>
<span id="cb30-753"><a href="#cb30-753" aria-hidden="true" tabindex="-1"></a>Indeed, the LabelMe dataset has only up to three votes per task whereas CIFAR-10H accounts for nearly fifty votes per task.</span>
<span id="cb30-754"><a href="#cb30-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-755"><a href="#cb30-755" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exploring tasks' difficulty</span></span>
<span id="cb30-756"><a href="#cb30-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-757"><a href="#cb30-757" aria-hidden="true" tabindex="-1"></a>To explore the tasks' intrinsic difficulty, we propose to compare three scoring metrics:</span>
<span id="cb30-758"><a href="#cb30-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-759"><a href="#cb30-759" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>the entropy of the NS distribution: reliable with a big enough and not adversarial crowd, the entropy measures the inherent uncertainty of the distribution to the possible outcomes.</span>
<span id="cb30-760"><a href="#cb30-760" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>GLAD's scoring: by construction, @whitehill_whose_2009 introduced a scalar coefficient to score the difficulty of a task $\beta_i&gt;0$.</span>
<span id="cb30-761"><a href="#cb30-761" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>the WAUM: introduced in <span class="co">[</span><span class="ot">@lefort2022improve</span><span class="co">]</span>, this weighted area under the margins indicates how difficult it is for a model to classify the task given the crowdsourced labels and the trust we have in each worker.</span>
<span id="cb30-762"><a href="#cb30-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-763"><a href="#cb30-763" aria-hidden="true" tabindex="-1"></a>Note that each of these statistics is useful in its context. The entropy can not be used in a setting with small $|\mathcal{A}(x_i)|$ (few labels per task), in particular for the LabelMe dataset it is uninformative.</span>
<span id="cb30-764"><a href="#cb30-764" aria-hidden="true" tabindex="-1"></a>The WAUM can handle any number of labels, but the larger the better. However, as it uses a deep learning classifier, the WAUM needs the tasks $(x_i)_i$ in addition to the proposed labels while the other strategies are feature-blind.</span>
<span id="cb30-765"><a href="#cb30-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-766"><a href="#cb30-766" aria-hidden="true" tabindex="-1"></a><span class="fu">### CIFAR-1OH dataset</span></span>
<span id="cb30-767"><a href="#cb30-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-768"><a href="#cb30-768" aria-hidden="true" tabindex="-1"></a>First, let us consider a dataset with a large number of tasks, annotations and workers: the CIFAR-10H dataset by @peterson_human_2019.</span>
<span id="cb30-769"><a href="#cb30-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-772"><a href="#cb30-772" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-773"><a href="#cb30-773" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-774"><a href="#cb30-774" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Example of images to label from the CIFAR-10H dataset with label `bird`, `car`, `cat`, `deer `and `dog` (top to bottom) by row.</span></span>
<span id="cb30-775"><a href="#cb30-775" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb30-776"><a href="#cb30-776" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-777"><a href="#cb30-777" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb30-778"><a href="#cb30-778" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb30-779"><a href="#cb30-779" aria-hidden="true" tabindex="-1"></a>nrow <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb30-780"><a href="#cb30-780" aria-hidden="true" tabindex="-1"></a>ncol <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb30-781"><a href="#cb30-781" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(</span>
<span id="cb30-782"><a href="#cb30-782" aria-hidden="true" tabindex="-1"></a>        nrow,</span>
<span id="cb30-783"><a href="#cb30-783" aria-hidden="true" tabindex="-1"></a>        ncol,</span>
<span id="cb30-784"><a href="#cb30-784" aria-hidden="true" tabindex="-1"></a>        sharey<span class="op">=</span><span class="st">"row"</span>,</span>
<span id="cb30-785"><a href="#cb30-785" aria-hidden="true" tabindex="-1"></a>        sharex<span class="op">=</span><span class="st">"col"</span>,</span>
<span id="cb30-786"><a href="#cb30-786" aria-hidden="true" tabindex="-1"></a>        figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">8</span>)</span>
<span id="cb30-787"><a href="#cb30-787" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-788"><a href="#cb30-788" aria-hidden="true" tabindex="-1"></a>match_ <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"bird"</span>, <span class="dv">1</span>: <span class="st">"car"</span>, <span class="dv">2</span>: <span class="st">"cat"</span>, <span class="dv">3</span>: <span class="st">"deer"</span>, <span class="dv">4</span>: <span class="st">"dog"</span>, <span class="dv">5</span>: <span class="st">"frog"</span>, <span class="dv">6</span>: <span class="st">"horse"</span>, <span class="dv">7</span>: <span class="st">"plane"</span>, <span class="dv">8</span>: <span class="st">"ship"</span>, <span class="dv">9</span>: <span class="st">"truck"</span>}</span>
<span id="cb30-789"><a href="#cb30-789" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"cifar10H"</span> <span class="op">/</span> <span class="st">"train"</span></span>
<span id="cb30-790"><a href="#cb30-790" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nrow):</span>
<span id="cb30-791"><a href="#cb30-791" aria-hidden="true" tabindex="-1"></a>  img_folder <span class="op">=</span> path <span class="op">/</span> <span class="ss">f"</span><span class="sc">{</span>match_[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb30-792"><a href="#cb30-792" aria-hidden="true" tabindex="-1"></a>  all_imgs <span class="op">=</span> <span class="bu">list</span>(img_folder.glob(<span class="st">"*"</span>))[:ncol]</span>
<span id="cb30-793"><a href="#cb30-793" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(ncol):</span>
<span id="cb30-794"><a href="#cb30-794" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> np.asarray(Image.<span class="bu">open</span>(path <span class="op">/</span> all_imgs[j]))</span>
<span id="cb30-795"><a href="#cb30-795" aria-hidden="true" tabindex="-1"></a>    axs[i,j].imshow(image, aspect<span class="op">=</span><span class="st">"equal"</span>)</span>
<span id="cb30-796"><a href="#cb30-796" aria-hidden="true" tabindex="-1"></a>    axs[i,j].axis(<span class="st">"off"</span>)</span>
<span id="cb30-797"><a href="#cb30-797" aria-hidden="true" tabindex="-1"></a>    axs[i,j].set_yticklabels([])</span>
<span id="cb30-798"><a href="#cb30-798" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=</span><span class="fl">0.05</span>, bottom<span class="op">=</span><span class="fl">0.05</span>, right<span class="op">=</span><span class="fl">0.95</span>, top<span class="op">=</span><span class="fl">0.95</span>, wspace<span class="op">=</span><span class="fl">0.05</span>, hspace<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb30-799"><a href="#cb30-799" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-800"><a href="#cb30-800" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-801"><a href="#cb30-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-802"><a href="#cb30-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-805"><a href="#cb30-805" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-806"><a href="#cb30-806" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-807"><a href="#cb30-807" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb30-808"><a href="#cb30-808" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>cifar10H <span class="op">-</span>s entropy <span class="op">-</span>K <span class="dv">10</span> <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span>answers.json</span>
<span id="cb30-809"><a href="#cb30-809" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span> <span class="op">-</span>s GLAD</span>
<span id="cb30-810"><a href="#cb30-810" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-813"><a href="#cb30-813" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-814"><a href="#cb30-814" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-815"><a href="#cb30-815" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-difficulty-c10H</span></span>
<span id="cb30-816"><a href="#cb30-816" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Comparison of metrics scoring the task's intrinsic difficulty in CIFAR-10H dataset.</span></span>
<span id="cb30-817"><a href="#cb30-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-818"><a href="#cb30-818" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb30-819"><a href="#cb30-819" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> corrfunc(x, y, ax<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kws):</span>
<span id="cb30-820"><a href="#cb30-820" aria-hidden="true" tabindex="-1"></a>    r, _ <span class="op">=</span> pearsonr(x, y)</span>
<span id="cb30-821"><a href="#cb30-821" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> ax <span class="kw">or</span> plt.gca()</span>
<span id="cb30-822"><a href="#cb30-822" aria-hidden="true" tabindex="-1"></a>    ax.annotate(<span class="vs">rf'Corr. = </span><span class="sc">{</span>r<span class="sc">:.2f}</span><span class="vs">'</span>, xy<span class="op">=</span>(<span class="fl">.1</span>, <span class="fl">.9</span>), xycoords<span class="op">=</span>ax.transAxes)</span>
<span id="cb30-823"><a href="#cb30-823" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">'GLAD difficulty'</span>: [], <span class="st">"Entropy"</span>: []}</span>
<span id="cb30-824"><a href="#cb30-824" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"cifar10H"</span> <span class="op">/</span> <span class="st">"identification"</span></span>
<span id="cb30-825"><a href="#cb30-825" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"Entropy"</span>] <span class="op">=</span> np.load(path <span class="op">/</span> <span class="st">'entropies.npy'</span>)</span>
<span id="cb30-826"><a href="#cb30-826" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"GLAD difficulty"</span>] <span class="op">=</span> np.exp(np.load(path <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"difficulties.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb30-827"><a href="#cb30-827" aria-hidden="true" tabindex="-1"></a><span class="co"># results["waum"] = pd.read_csv(path / "resnet34" / "waum_0.01_yang" / 'waum.csv')["waum"].values</span></span>
<span id="cb30-828"><a href="#cb30-828" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb30-829"><a href="#cb30-829" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb30-830"><a href="#cb30-830" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb30-831"><a href="#cb30-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-832"><a href="#cb30-832" aria-hidden="true" tabindex="-1"></a><span class="co"># axes = g.axes.flatten()</span></span>
<span id="cb30-833"><a href="#cb30-833" aria-hidden="true" tabindex="-1"></a><span class="co"># for i, ax in enumerate(axes):</span></span>
<span id="cb30-834"><a href="#cb30-834" aria-hidden="true" tabindex="-1"></a><span class="co">#   if i % len(results) == 0:</span></span>
<span id="cb30-835"><a href="#cb30-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-836"><a href="#cb30-836" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-837"><a href="#cb30-837" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-838"><a href="#cb30-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-839"><a href="#cb30-839" aria-hidden="true" tabindex="-1"></a><span class="fu">### LabelMe dataset</span></span>
<span id="cb30-840"><a href="#cb30-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-841"><a href="#cb30-841" aria-hidden="true" tabindex="-1"></a>As for the LabelMe dataset, one difficulty in evaluating tasks' intrinsic difficulty is that there are up to three votes given per task.</span>
<span id="cb30-842"><a href="#cb30-842" aria-hidden="true" tabindex="-1"></a>Hence, the entropy in the distribution of the votes is no longer a reliable metric, and we need to rely on other models.</span>
<span id="cb30-843"><a href="#cb30-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-846"><a href="#cb30-846" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-847"><a href="#cb30-847" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-848"><a href="#cb30-848" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Example of images to label from the LabelMe dataset with label `coast`, `forest`, `highway`, `insidecity `and `mountain` (top to bottom) by row.</span></span>
<span id="cb30-849"><a href="#cb30-849" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb30-850"><a href="#cb30-850" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-851"><a href="#cb30-851" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb30-852"><a href="#cb30-852" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb30-853"><a href="#cb30-853" aria-hidden="true" tabindex="-1"></a>nrow <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb30-854"><a href="#cb30-854" aria-hidden="true" tabindex="-1"></a>ncol <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb30-855"><a href="#cb30-855" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(</span>
<span id="cb30-856"><a href="#cb30-856" aria-hidden="true" tabindex="-1"></a>        nrow,</span>
<span id="cb30-857"><a href="#cb30-857" aria-hidden="true" tabindex="-1"></a>        ncol,</span>
<span id="cb30-858"><a href="#cb30-858" aria-hidden="true" tabindex="-1"></a>        sharey<span class="op">=</span><span class="st">"row"</span>,</span>
<span id="cb30-859"><a href="#cb30-859" aria-hidden="true" tabindex="-1"></a>        sharex<span class="op">=</span><span class="st">"col"</span>,</span>
<span id="cb30-860"><a href="#cb30-860" aria-hidden="true" tabindex="-1"></a>        figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">8</span>)</span>
<span id="cb30-861"><a href="#cb30-861" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-862"><a href="#cb30-862" aria-hidden="true" tabindex="-1"></a>match_ <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"coast"</span>, <span class="dv">1</span>: <span class="st">"forest"</span>, <span class="dv">2</span>: <span class="st">"highway"</span>, <span class="dv">3</span>: <span class="st">"insidecity"</span>, <span class="dv">4</span>: <span class="st">"mountain"</span>, <span class="dv">5</span>: <span class="st">"opencountry"</span>, <span class="dv">6</span>: <span class="st">"street"</span>, <span class="dv">7</span>: <span class="st">"tallbuilding"</span>}</span>
<span id="cb30-863"><a href="#cb30-863" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"labelme"</span> <span class="op">/</span> <span class="st">"train"</span></span>
<span id="cb30-864"><a href="#cb30-864" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nrow):</span>
<span id="cb30-865"><a href="#cb30-865" aria-hidden="true" tabindex="-1"></a>  img_folder <span class="op">=</span> path <span class="op">/</span> <span class="ss">f"</span><span class="sc">{</span>match_[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb30-866"><a href="#cb30-866" aria-hidden="true" tabindex="-1"></a>  all_imgs <span class="op">=</span> <span class="bu">list</span>(img_folder.glob(<span class="st">"*"</span>))[:ncol]</span>
<span id="cb30-867"><a href="#cb30-867" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(ncol):</span>
<span id="cb30-868"><a href="#cb30-868" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> np.asarray(Image.<span class="bu">open</span>(path <span class="op">/</span> all_imgs[j]))</span>
<span id="cb30-869"><a href="#cb30-869" aria-hidden="true" tabindex="-1"></a>    axs[i,j].imshow(image, aspect<span class="op">=</span><span class="st">"equal"</span>)</span>
<span id="cb30-870"><a href="#cb30-870" aria-hidden="true" tabindex="-1"></a>    axs[i,j].axis(<span class="st">"off"</span>)</span>
<span id="cb30-871"><a href="#cb30-871" aria-hidden="true" tabindex="-1"></a>    axs[i,j].set_yticklabels([])</span>
<span id="cb30-872"><a href="#cb30-872" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(left<span class="op">=</span><span class="fl">0.05</span>, bottom<span class="op">=</span><span class="fl">0.05</span>, right<span class="op">=</span><span class="fl">0.95</span>, top<span class="op">=</span><span class="fl">0.95</span>, wspace<span class="op">=</span><span class="fl">0.05</span>, hspace<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb30-873"><a href="#cb30-873" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-874"><a href="#cb30-874" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-875"><a href="#cb30-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-876"><a href="#cb30-876" aria-hidden="true" tabindex="-1"></a>Now, let us compare the tasks' difficulty distribution depending on the strategy considered using <span class="in">`peerannot`</span>.</span>
<span id="cb30-877"><a href="#cb30-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-880"><a href="#cb30-880" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-881"><a href="#cb30-881" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-882"><a href="#cb30-882" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb30-883"><a href="#cb30-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-884"><a href="#cb30-884" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">-</span>s entropy <span class="op">-</span>K <span class="dv">10</span> <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span>answers.json</span>
<span id="cb30-885"><a href="#cb30-885" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">-</span>s GLAD</span>
<span id="cb30-886"><a href="#cb30-886" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-887"><a href="#cb30-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-888"><a href="#cb30-888" aria-hidden="true" tabindex="-1"></a>We can see in @fig-difficulty-labelme that because the number of labels given per task is in $<span class="sc">\{</span>1,2,3<span class="sc">\}</span>$, the entropy only takes four values and thus does not help to dissociate the tasks.</span>
<span id="cb30-889"><a href="#cb30-889" aria-hidden="true" tabindex="-1"></a>In particular, tasks with only one label all have a null entropy, so not just consensual tasks.</span>
<span id="cb30-890"><a href="#cb30-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-893"><a href="#cb30-893" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-894"><a href="#cb30-894" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-895"><a href="#cb30-895" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-difficulty-labelme</span></span>
<span id="cb30-896"><a href="#cb30-896" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Comparison of metrics scoring the task's intrinsic difficulty.</span></span>
<span id="cb30-897"><a href="#cb30-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-898"><a href="#cb30-898" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb30-899"><a href="#cb30-899" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> corrfunc(x, y, ax<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kws):</span>
<span id="cb30-900"><a href="#cb30-900" aria-hidden="true" tabindex="-1"></a>    r, _ <span class="op">=</span> pearsonr(x, y)</span>
<span id="cb30-901"><a href="#cb30-901" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> ax <span class="kw">or</span> plt.gca()</span>
<span id="cb30-902"><a href="#cb30-902" aria-hidden="true" tabindex="-1"></a>    ax.annotate(<span class="vs">rf'Corr. = </span><span class="sc">{</span>r<span class="sc">:.2f}</span><span class="vs">'</span>, xy<span class="op">=</span>(<span class="fl">.1</span>, <span class="fl">.1</span>), xycoords<span class="op">=</span>ax.transAxes)</span>
<span id="cb30-903"><a href="#cb30-903" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">'GLAD difficulty'</span>: [], <span class="st">"Entropy"</span>: []}</span>
<span id="cb30-904"><a href="#cb30-904" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"labelme"</span> <span class="op">/</span> <span class="st">"identification"</span></span>
<span id="cb30-905"><a href="#cb30-905" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"Entropy"</span>] <span class="op">=</span> np.load(path <span class="op">/</span> <span class="st">'entropies.npy'</span>)</span>
<span id="cb30-906"><a href="#cb30-906" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"GLAD difficulty"</span>] <span class="op">=</span> np.exp(np.load(path <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"difficulties.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb30-907"><a href="#cb30-907" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(results)</span>
<span id="cb30-908"><a href="#cb30-908" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb30-909"><a href="#cb30-909" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb30-910"><a href="#cb30-910" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-911"><a href="#cb30-911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-912"><a href="#cb30-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-913"><a href="#cb30-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-914"><a href="#cb30-914" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exploring workers' reliability</span></span>
<span id="cb30-915"><a href="#cb30-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-916"><a href="#cb30-916" aria-hidden="true" tabindex="-1"></a>From the labels, we can explore different worker evaluation scores.</span>
<span id="cb30-917"><a href="#cb30-917" aria-hidden="true" tabindex="-1"></a>GLAD's strategy estimates a reliability scalar coefficient $\alpha_j$ per worker.</span>
<span id="cb30-918"><a href="#cb30-918" aria-hidden="true" tabindex="-1"></a>With strategies looking to estimate confusion matrices, we investigate two scoring rules for workers:</span>
<span id="cb30-919"><a href="#cb30-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-920"><a href="#cb30-920" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the trace of the confusion matrix: the closer to K the better the worker,</span>
<span id="cb30-921"><a href="#cb30-921" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the spammer score <span class="co">[</span><span class="ot">@raykar_ranking_2011</span><span class="co">]</span> that is the Frobenius norm between the estimated confusion matrix $\hat\pi^{(j)}$ and the closest rank-$1$ matrix. The further to zero the better the worker.</span>
<span id="cb30-922"><a href="#cb30-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-923"><a href="#cb30-923" aria-hidden="true" tabindex="-1"></a>When the tasks are available, confusion-matrix-based deep learning models can also be of use.</span>
<span id="cb30-924"><a href="#cb30-924" aria-hidden="true" tabindex="-1"></a>We thus add to the comparison the trace of the confusion matrices with CrowdLayer and CoNAL on the datasets.</span>
<span id="cb30-925"><a href="#cb30-925" aria-hidden="true" tabindex="-1"></a>For CoNAL, we only consider the trace of the confusion matrix $\pi^{(j)}$ in the pairwise comparison, and provide the common confusion matrix $\pi^g$ as separate.</span>
<span id="cb30-926"><a href="#cb30-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-927"><a href="#cb30-927" aria-hidden="true" tabindex="-1"></a><span class="fu">### CIFAR-10H</span></span>
<span id="cb30-928"><a href="#cb30-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-929"><a href="#cb30-929" aria-hidden="true" tabindex="-1"></a>The Cifar-10H dataset has few disagreements among workers.</span>
<span id="cb30-930"><a href="#cb30-930" aria-hidden="true" tabindex="-1"></a>From @fig-abilities-cifar10H, we can see that in this dataset, different methods easily separate the worse workers from the rest of the crowd (workers in the tail of the distribution).</span>
<span id="cb30-931"><a href="#cb30-931" aria-hidden="true" tabindex="-1"></a>However, these strategies disagree on the ranking of good against best workers as they do not measure the same properties.</span>
<span id="cb30-932"><a href="#cb30-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-935"><a href="#cb30-935" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-936"><a href="#cb30-936" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-937"><a href="#cb30-937" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb30-938"><a href="#cb30-938" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span> <span class="op">-</span>s GLAD</span>
<span id="cb30-939"><a href="#cb30-939" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method <span class="kw">in</span> [<span class="st">"trace_confusion"</span>, <span class="st">"spam_score"</span>]:</span>
<span id="cb30-940"><a href="#cb30-940" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span> <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb30-941"><a href="#cb30-941" aria-hidden="true" tabindex="-1"></a>                       <span class="op">-</span>s {method} <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>cifar10H<span class="op">/</span>answers.json</span>
<span id="cb30-942"><a href="#cb30-942" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-943"><a href="#cb30-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-946"><a href="#cb30-946" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-947"><a href="#cb30-947" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-abilities-cifar10H</span></span>
<span id="cb30-948"><a href="#cb30-948" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-949"><a href="#cb30-949" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Comparison of ability scores by workers for the CIFAR-10H dataset.</span></span>
<span id="cb30-950"><a href="#cb30-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-951"><a href="#cb30-951" aria-hidden="true" tabindex="-1"></a>path_ <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"cifar10H"</span></span>
<span id="cb30-952"><a href="#cb30-952" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> {<span class="st">"trace_confusion"</span>: [], <span class="st">"spam_score"</span>: [], <span class="st">"glad"</span>: []}</span>
<span id="cb30-953"><a href="#cb30-953" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"trace_confusion"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"traces_confusion.npy"</span>))</span>
<span id="cb30-954"><a href="#cb30-954" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"spam_score"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"spam_score.npy"</span>))</span>
<span id="cb30-955"><a href="#cb30-955" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"glad"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"abilities.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb30-956"><a href="#cb30-956" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> pd.DataFrame(results_identif)</span>
<span id="cb30-957"><a href="#cb30-957" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results_identif, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb30-958"><a href="#cb30-958" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb30-959"><a href="#cb30-959" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-960"><a href="#cb30-960" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-961"><a href="#cb30-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-962"><a href="#cb30-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-963"><a href="#cb30-963" aria-hidden="true" tabindex="-1"></a><span class="fu">### LabelMe</span></span>
<span id="cb30-964"><a href="#cb30-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-965"><a href="#cb30-965" aria-hidden="true" tabindex="-1"></a>Finally, let us evaluate workers for the LabelMe dataset.</span>
<span id="cb30-966"><a href="#cb30-966" aria-hidden="true" tabindex="-1"></a>Because of the lack of data,</span>
<span id="cb30-967"><a href="#cb30-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-970"><a href="#cb30-970" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-971"><a href="#cb30-971" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb30-972"><a href="#cb30-972" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb30-973"><a href="#cb30-973" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> peerannot aggregate .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">-</span>s GLAD</span>
<span id="cb30-974"><a href="#cb30-974" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method <span class="kw">in</span> [<span class="st">"trace_confusion"</span>, <span class="st">"spam_score"</span>]:</span>
<span id="cb30-975"><a href="#cb30-975" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span> peerannot identify .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span> <span class="op">--</span>n<span class="op">-</span>classes<span class="op">=</span><span class="dv">10</span> <span class="op">\</span></span>
<span id="cb30-976"><a href="#cb30-976" aria-hidden="true" tabindex="-1"></a>                       <span class="op">-</span>s {method} <span class="op">--</span>labels .<span class="op">/</span>datasets<span class="op">/</span>labelme<span class="op">/</span>answers.json</span>
<span id="cb30-977"><a href="#cb30-977" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-978"><a href="#cb30-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-981"><a href="#cb30-981" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb30-982"><a href="#cb30-982" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb30-983"><a href="#cb30-983" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-abilities-labelme</span></span>
<span id="cb30-984"><a href="#cb30-984" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Comparison of ability scores by workers for the labelme dataset.</span></span>
<span id="cb30-985"><a href="#cb30-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-986"><a href="#cb30-986" aria-hidden="true" tabindex="-1"></a>path_ <span class="op">=</span> Path.cwd() <span class="op">/</span> <span class="st">"datasets"</span> <span class="op">/</span> <span class="st">"labelme"</span></span>
<span id="cb30-987"><a href="#cb30-987" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> {<span class="st">"trace_confusion"</span>: [], <span class="st">"spam_score"</span>: [], <span class="st">"glad"</span>: []}</span>
<span id="cb30-988"><a href="#cb30-988" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"trace_confusion"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"traces_confusion.npy"</span>))</span>
<span id="cb30-989"><a href="#cb30-989" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"spam_score"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"spam_score.npy"</span>))</span>
<span id="cb30-990"><a href="#cb30-990" aria-hidden="true" tabindex="-1"></a>results_identif[<span class="st">"glad"</span>].extend(np.load(path_ <span class="op">/</span> <span class="st">'identification'</span> <span class="op">/</span> <span class="st">"glad"</span> <span class="op">/</span> <span class="st">"abilities.npy"</span>)[:, <span class="dv">1</span>])</span>
<span id="cb30-991"><a href="#cb30-991" aria-hidden="true" tabindex="-1"></a>results_identif <span class="op">=</span> pd.DataFrame(results_identif)</span>
<span id="cb30-992"><a href="#cb30-992" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.pairplot(results_identif, corner<span class="op">=</span><span class="va">True</span>, diag_kind<span class="op">=</span><span class="st">"kde"</span>, plot_kws<span class="op">=</span>{<span class="st">'alpha'</span>:<span class="fl">0.2</span>})</span>
<span id="cb30-993"><a href="#cb30-993" aria-hidden="true" tabindex="-1"></a>g.map_lower(corrfunc)</span>
<span id="cb30-994"><a href="#cb30-994" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-995"><a href="#cb30-995" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb30-996"><a href="#cb30-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-997"><a href="#cb30-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-998"><a href="#cb30-998" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb30-999"><a href="#cb30-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-1000"><a href="#cb30-1000" aria-hidden="true" tabindex="-1"></a>We introduced <span class="in">`peerannot`</span>, a library to handle crowdsourced datasets. This library enables both easy label aggregation and direct training strategies with classical state-of-the-art classifiers. The identification module of the library allows exploring the collected data from both the tasks and the workers' point of view for better scorings and data cleaning procedures.</span>
<span id="cb30-1001"><a href="#cb30-1001" aria-hidden="true" tabindex="-1"></a>Our library also comes with templated datasets to better share crowdsourced datasets and have strategies more uniform to test on.</span>
<span id="cb30-1002"><a href="#cb30-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-1003"><a href="#cb30-1003" aria-hidden="true" tabindex="-1"></a>We hope that this library helps reproducibility in the crowdsourcing community and also standardizes training from crowdsourced datasets. New strategies can easily be incorporated into the open-source code <span class="co">[</span><span class="ot">available on github</span><span class="co">](https://github.com/peerannot/peerannot)</span>. Finally, as <span class="in">`peerannot`</span> is mostly directed to handle classification datasets, one of our future works would be to consider other <span class="in">`peerannot`</span> modules to handle crowdsourcing for object detection, segmentation and even worker evaluation in other contexts like peer-grading.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>